{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Background Operation ID is a ministry that exists to serve the need of individuals who need to obtain identification documents to support their application for a variety of services from housing to job application. The ministry is volunteer driven and has been in place for over thirty years. During this time thousands of individuals have received help to support their identification needs. Help is provided in the form of vouchers that can be used to pay for services rendered by either the Texas Department of Public Safety for a Texas ID or by the Bureau of Vital Statistics of Texas or another state to acquire a certified copy of a birth certificate. Over the years of Operation ID's existence various paper driven pipelines of client processing in providing identification services have been used. The currently existing pipeline consists of four stages which are executed sequentially. Screening Check In Interviewing Back Office Voucher Writing In the Screening stage, a client is greeted at the front desk by a volunteer who checks that the client's referral letter is valid and that the documents the client possesses support the services they are seeking. The referral letter is provided by the agency representing the client to Operation ID and this agency performs the first level of screening. If this first level of screening is done carefully, the Screening stage at Operation ID can proceed very quickly, allowing the client to proceed to the Check In stage. The referral letter must specify the services that a client is seeking at Operation ID. In the Check In stage (also performed by a volunteer at the front desk) the client is entered into the Operation ID database if he/she is not already in the database. The database is maintained by the Apricot database driven application software provided by the vendor Social Solutions . Apricot is used to capture a client's demographic data together with a history of a client's previous visits to Operation ID. The demographic data includes a client's name, date of birth and age (a calculated field based on date of birth). The demographic data also includes a link to a household table, if a client is part of a household being processed together. Apricot stores basic demographic data in a table it refers to as the Client Tracking table and stores client visits in a related table called the Client Tracking Document Folder. (In terms of database technology, the Client Tracking Document Folder is related to the Client Tracking table by a foreign key.) Operation ID makes use of the Client Tracking Document Folder to record services provided to a client during previous visits. Whenever a service is provided to a client (example: writing a check for a birth certificate), the service is recorded by date together with the number of any issued check. At a date after the date of service, the disposition of an issued check is recorded. Most often this disposition will be either Cleared, indicating that the check has been used by the client or Voided, indicating that the check is no longer valid. During the Check In stage at the front desk, a client's history of previous visits (if any) is manually copied onto a small slip of paper which is then stapled to the client's referral letter. Previous visits may make a client ineligible for a service being requested. Operation ID enforces a twice-in-a-lifetime policy for birth certificate or ID services. If a client's history of previous visits reveals that they have twice previously been issued checks for a birth certificate and both checks have been used, then the client is not eligible for another check for a birth certificate. Similarly, if a client has twice previously been issued checks for an ID (either a Texas ID or a Texas Driver's License) and both checks have been used, then they are not eligible for another check for an ID. If a client is ineligible for a requested service, then they are so informed at the front desk. A client ineligible for a requested service may appeal their ineligibility and may, at the discretion of Operation ID management, be granted an exception. Most clients are either first time clients (no previous visit history) or clients who have not yet exhausted eligibility for a requested service. In either case, such a client is ready for the Interviewing stage. A client ready to be interviewed may have to wait for a (volunteer) interviewer to become available. Clients are processed on a first-come-first-served basis and frequently have to wait for an available interviewer. When an interviewer picks up a waiting client, the client's requested services are reviewed and paperwork in support of these services is completed. If the client is representing themselves alone, the paperwork generation may go fairly quickly. If the client is requesting an out-of-state birth certificate, more time is required, because the paperwork required to acquire a certified birth certificate varies from state to state. If the client represents a household, then paperwork for each member of the household is required and this may slow down the interviewing process considerably. In any event, under the current client processing pipeline, all paperwork required is completed during the interviewing process before the back office can generate any voucher for a client. When paperwork filled out during the Interviewing stage is sent to the back office, the Back Office Voucher Writing stage may begin. This stage may not begin immediately upon the delivery of the completed paperwork for a given client, because a backlog of previous clients may need to be processed first. When a client's paperwork is eventually processed by the back office, what remains to be done is straightforward. A voucher for each service requested by a client is first generated by use of Quickbooks (operated by a volunteer). Then the voucher number of each generated voucher is recorded in the Apricot database (by another volunteer) in the client's visit history. This record keeping step is what enables enforcement of the twice-in-a-lifetime service policy mentioned above. After vouchers have been generated and recorded, they are delivered to the client and the pipeline of client processing is completed. What has been described above may be referred to as the same-day-service model of client processing. An alternative model, Remote Operation ID, will be described in a section below. Remote Operation ID will be described as a virtual platform providing the same client services without the need for a client to appear at Operation ID. The OPIDDaily Website The OPIDDaily website was designed to partially automate the pipeline of client processing at Operation ID by allowing the back office production of vouchers to proceed in parallel with the interviewing of clients to generate paperwork supporting their needs. OPIDDaily takes advantage of the fact that a client's voucher needs are already known during the Screening and Check In stages. This allows the front desk volunteers to send the back office volunteers information which allows the Back Office Voucher Writing stage to begin, possibly even before the Interviewing Stage has started. In support of parallel processing using OPIDDaily a Service Ticket describing a client's previous visits (if any) together with the services the client is seeking is printed on a printer at the front desk by the front desk check in volunteer. It has been suggested that in straightforward cases this Service Ticket be sent directly to the back office so that back office volunteers could begin processing the service requested on the Service Ticket in advance of the Interviewing stage being completed. In effect, the Interviewing stage and the Back Office Voucher Writing stage would be run in parallel. This has the potential of delivering substantial time savings over the currently existing sequential pipeline. The Screening and Check In stages would require a small amount of additional time in order to generate the Service Ticket for a client, but this extra time would be more than compensated for by the ability to run the Interviewing and Back Office Voucher Writing stages in parallel. In practice, a Service Ticket is not issued for each client appearing at the front desk on a day of service. Instead, in order to keep the line moving, a Service Ticket is only generated for clients with a history of previous visits. Clients with no previous visits are quickly moved through the front desk after their name and date of birth have been recorded in the Apricot database. The Service Ticket generated for a client with a visit history is attached to the client's referral letter rather than being sent to the back office. This does not take advantage of the parallel processing mentioned above, but it has nevertheless proved to be valuable. A client's referral letter must contain the services the client is seeking. A Service Ticket for a client with previous history summarizes the requested services in a tabular format. Remote Operation ID In March 2020 Operation ID was shutdown due to the coronavirus pandemic. At the time of this writing (April 2020) Operation ID is still shut down and it is not known when it will reopen. When the shutdown began, work was begun on a simple extension of OPIDDaily that would allow for providing identification services remotely. Remote operation replaces the same-day-service model of identification services that have historically been provided by Operation ID by a virtual platform that allows case managers to submit service requests to Operation ID through the OPIDDaily website. The service request replaces the referral letter used in the same-day-service model described above. Under the same-day-service model, there is only a single logged in user, the TicketMaster . The TicketMaster is a volunteer who sits at the front desk and uses OPIDDaily to generate a Service Ticket for each client with a history of previous visits. In the remote service model, case managers who work at Operation ID partner agencies login to the OPIDDaily website to submit service requests on behalf of their clients. The last step of generating a service request for a client is the printing and signing of the Case Manager Voucher . The Case Manager Voucher is a piece of paper describing the service request. It includes a disclaimer that makes the client aware that requested services may be denied because of previous visits to Operation ID for the same services. The Case Manager Voucher must be signed by both the client and the case manager. The voucher will be retained by the case manager, who will later redeem it for checks covering the requested services. A service request submitted by a case manager appears on a dashboard monitored by an Operation ID employee. The dashboard is simply a list of service requests placed by case managers working at different agencies. When a new service request appears on the dashboard, its arrival is first acknowledged by checking a checkbox on the request. This acknowledgment will be seen by the case manager who placed the request, informing him/her that Operation ID is aware of the request. The service request will next be used to generate a Service Ticket which will be printed and added to a collection of outstanding Service Tickets. When Service Tickets representing enough clients have been accumulated, the status of each represented client will be changed to BackOffice, indicating that the service requests have been passed to the back office at Operation ID for processing. The respective case managers will see this change in status for their clients. Processing a Service Ticket in the back office is exactly the same process that takes place in the same-day-service model. It involves using Quickbooks to cut checks for services specified by a Service Ticket and recording the check numbers in the corresponding client database entry in the Apricot database. This processing will be handled by an Operation ID volunteer, as is done in the same-day-service model. Once the check(s) have been cut for a client, the Operation ID employee monitoring the dashboard changes the client's status to Done indicating to the client's case manager that processing has completed and checks may be picked up at the Operation ID office. The checks will be released to a case manager as redemption of the corresponding Case Manager Voucher. The process of remote operation described above involves only the case manager and Operation ID personnel. A client works with his/her case manager to generate a service request and then waits for the checks to be picked up at Operation ID by the case manager. Unlike the same-day-service model, the client never appears at Operation ID. This will be especially important as long as the same-day-service operation remains shut down. The Remote Operation ID process clearly requires more time to complete than the same-day-service model. As a practical matter, a Case Manager Voucher will indicate a 30 day period of validity. This is actually a time limit on how long Operation ID is given to respond to the corresponding service request once it appears on the OPIDDaily dashboard. The dashboard list will be sorted in chronological order of service request expiration dates. A service request will automatically roll off the dashboard once its expiration date has passed. Service History A Service Ticket lists not only the services a client is requesting but also the services the client has received in prior visits (if any). Listing previous services rendered is made possible by including a table of previously issued checks in the OPIDDaily database. Each record in the table of checks contains a check number, the check purpose, the name of the client to whom the check was issued and the disposition of the check, whether it was Cleared by the bank, Voided by the bank or one of several dispositions private to Operation ID. A check record does not include who the payee of the check is or the amount of the check. The check is referenced to the Apricot database simply by its unique number, not by the name of the client to whom the check was given. Periodically a pair of back office reports is processed by OPIDDaily to update its table of checks with the bank declared disposition of checks. These reports are generated by Quickbooks. One report lists check numbers of Cleared checks and the other report lists check numbers of Voided checks. This updating of the OPIDDaily table of checks implies that check numbers are recorded in the OPIDDaily database before their dispositions are known. This is indeed the case. To effect this, a report is periodically exported from the Apricot database and processed by OPIDDaily to import issued check into the OPIDDaily table of checks. By consulting the table of checks in the OPIDDaily database, it is possible to produce a service history for a client. A client with a service history is referred to as an Existing Client and a client with no previous service history is referred to as an Express Client. The term express client was chosen to imply that such a client's service request would be both easier and faster to process in the historic same-day-service model. As explained above, in practice a Service Ticket for an Express Client is not generated. In the remote operation model, a Service Ticket will be generated at Operation ID for both Existing Clients and Express Clients. Since there will be no referral letter under this model, the Service Ticket will be the only means of specifying requested services. Frequently a client will return to Operation ID requesting service before the disposition of a check previously issued to the client is known. In such a case, a back office volunteer will need to consult a Quickbooks ledger to determine the check's disposition. If the disposition can be determined, it may affect the service request by the client. In the same-day-service model, a client may need to be informed the he/she is not eligible for a requested service, because they have exhausted their twice-in-a-lifetime eligibility. This is sometimes a difficult conversation, especially if the client has endured a long line only to learn they are not eligible for the service they are requesting. In the remote operation model, Operation ID will convey ineligibility through the OPIDDaily website to a client's case manager. The case manager will then need to remind the client of the disclaimer about potential service denial that the client was made aware of when they signed their Case Manager Voucher. This Document OPIDDaily is available as a password protected website to registered users. This document describes the design and implementation of OPIDDaily. The Infrastructure tab describes how project OPIDDaily is maintained on a desktop host and how it is deployed to the .NET hosting service AppHarbor. The Database tab describes how the OPIDDaily database is managed on the desktop and at AppHarbor. The Implementation tab provides some details concerning the implementation of OPIDDaily.","title":"Background"},{"location":"#background","text":"Operation ID is a ministry that exists to serve the need of individuals who need to obtain identification documents to support their application for a variety of services from housing to job application. The ministry is volunteer driven and has been in place for over thirty years. During this time thousands of individuals have received help to support their identification needs. Help is provided in the form of vouchers that can be used to pay for services rendered by either the Texas Department of Public Safety for a Texas ID or by the Bureau of Vital Statistics of Texas or another state to acquire a certified copy of a birth certificate. Over the years of Operation ID's existence various paper driven pipelines of client processing in providing identification services have been used. The currently existing pipeline consists of four stages which are executed sequentially. Screening Check In Interviewing Back Office Voucher Writing In the Screening stage, a client is greeted at the front desk by a volunteer who checks that the client's referral letter is valid and that the documents the client possesses support the services they are seeking. The referral letter is provided by the agency representing the client to Operation ID and this agency performs the first level of screening. If this first level of screening is done carefully, the Screening stage at Operation ID can proceed very quickly, allowing the client to proceed to the Check In stage. The referral letter must specify the services that a client is seeking at Operation ID. In the Check In stage (also performed by a volunteer at the front desk) the client is entered into the Operation ID database if he/she is not already in the database. The database is maintained by the Apricot database driven application software provided by the vendor Social Solutions . Apricot is used to capture a client's demographic data together with a history of a client's previous visits to Operation ID. The demographic data includes a client's name, date of birth and age (a calculated field based on date of birth). The demographic data also includes a link to a household table, if a client is part of a household being processed together. Apricot stores basic demographic data in a table it refers to as the Client Tracking table and stores client visits in a related table called the Client Tracking Document Folder. (In terms of database technology, the Client Tracking Document Folder is related to the Client Tracking table by a foreign key.) Operation ID makes use of the Client Tracking Document Folder to record services provided to a client during previous visits. Whenever a service is provided to a client (example: writing a check for a birth certificate), the service is recorded by date together with the number of any issued check. At a date after the date of service, the disposition of an issued check is recorded. Most often this disposition will be either Cleared, indicating that the check has been used by the client or Voided, indicating that the check is no longer valid. During the Check In stage at the front desk, a client's history of previous visits (if any) is manually copied onto a small slip of paper which is then stapled to the client's referral letter. Previous visits may make a client ineligible for a service being requested. Operation ID enforces a twice-in-a-lifetime policy for birth certificate or ID services. If a client's history of previous visits reveals that they have twice previously been issued checks for a birth certificate and both checks have been used, then the client is not eligible for another check for a birth certificate. Similarly, if a client has twice previously been issued checks for an ID (either a Texas ID or a Texas Driver's License) and both checks have been used, then they are not eligible for another check for an ID. If a client is ineligible for a requested service, then they are so informed at the front desk. A client ineligible for a requested service may appeal their ineligibility and may, at the discretion of Operation ID management, be granted an exception. Most clients are either first time clients (no previous visit history) or clients who have not yet exhausted eligibility for a requested service. In either case, such a client is ready for the Interviewing stage. A client ready to be interviewed may have to wait for a (volunteer) interviewer to become available. Clients are processed on a first-come-first-served basis and frequently have to wait for an available interviewer. When an interviewer picks up a waiting client, the client's requested services are reviewed and paperwork in support of these services is completed. If the client is representing themselves alone, the paperwork generation may go fairly quickly. If the client is requesting an out-of-state birth certificate, more time is required, because the paperwork required to acquire a certified birth certificate varies from state to state. If the client represents a household, then paperwork for each member of the household is required and this may slow down the interviewing process considerably. In any event, under the current client processing pipeline, all paperwork required is completed during the interviewing process before the back office can generate any voucher for a client. When paperwork filled out during the Interviewing stage is sent to the back office, the Back Office Voucher Writing stage may begin. This stage may not begin immediately upon the delivery of the completed paperwork for a given client, because a backlog of previous clients may need to be processed first. When a client's paperwork is eventually processed by the back office, what remains to be done is straightforward. A voucher for each service requested by a client is first generated by use of Quickbooks (operated by a volunteer). Then the voucher number of each generated voucher is recorded in the Apricot database (by another volunteer) in the client's visit history. This record keeping step is what enables enforcement of the twice-in-a-lifetime service policy mentioned above. After vouchers have been generated and recorded, they are delivered to the client and the pipeline of client processing is completed. What has been described above may be referred to as the same-day-service model of client processing. An alternative model, Remote Operation ID, will be described in a section below. Remote Operation ID will be described as a virtual platform providing the same client services without the need for a client to appear at Operation ID.","title":"Background"},{"location":"#the-opiddaily-website","text":"The OPIDDaily website was designed to partially automate the pipeline of client processing at Operation ID by allowing the back office production of vouchers to proceed in parallel with the interviewing of clients to generate paperwork supporting their needs. OPIDDaily takes advantage of the fact that a client's voucher needs are already known during the Screening and Check In stages. This allows the front desk volunteers to send the back office volunteers information which allows the Back Office Voucher Writing stage to begin, possibly even before the Interviewing Stage has started. In support of parallel processing using OPIDDaily a Service Ticket describing a client's previous visits (if any) together with the services the client is seeking is printed on a printer at the front desk by the front desk check in volunteer. It has been suggested that in straightforward cases this Service Ticket be sent directly to the back office so that back office volunteers could begin processing the service requested on the Service Ticket in advance of the Interviewing stage being completed. In effect, the Interviewing stage and the Back Office Voucher Writing stage would be run in parallel. This has the potential of delivering substantial time savings over the currently existing sequential pipeline. The Screening and Check In stages would require a small amount of additional time in order to generate the Service Ticket for a client, but this extra time would be more than compensated for by the ability to run the Interviewing and Back Office Voucher Writing stages in parallel. In practice, a Service Ticket is not issued for each client appearing at the front desk on a day of service. Instead, in order to keep the line moving, a Service Ticket is only generated for clients with a history of previous visits. Clients with no previous visits are quickly moved through the front desk after their name and date of birth have been recorded in the Apricot database. The Service Ticket generated for a client with a visit history is attached to the client's referral letter rather than being sent to the back office. This does not take advantage of the parallel processing mentioned above, but it has nevertheless proved to be valuable. A client's referral letter must contain the services the client is seeking. A Service Ticket for a client with previous history summarizes the requested services in a tabular format.","title":"The OPIDDaily Website"},{"location":"#remote-operation-id","text":"In March 2020 Operation ID was shutdown due to the coronavirus pandemic. At the time of this writing (April 2020) Operation ID is still shut down and it is not known when it will reopen. When the shutdown began, work was begun on a simple extension of OPIDDaily that would allow for providing identification services remotely. Remote operation replaces the same-day-service model of identification services that have historically been provided by Operation ID by a virtual platform that allows case managers to submit service requests to Operation ID through the OPIDDaily website. The service request replaces the referral letter used in the same-day-service model described above. Under the same-day-service model, there is only a single logged in user, the TicketMaster . The TicketMaster is a volunteer who sits at the front desk and uses OPIDDaily to generate a Service Ticket for each client with a history of previous visits. In the remote service model, case managers who work at Operation ID partner agencies login to the OPIDDaily website to submit service requests on behalf of their clients. The last step of generating a service request for a client is the printing and signing of the Case Manager Voucher . The Case Manager Voucher is a piece of paper describing the service request. It includes a disclaimer that makes the client aware that requested services may be denied because of previous visits to Operation ID for the same services. The Case Manager Voucher must be signed by both the client and the case manager. The voucher will be retained by the case manager, who will later redeem it for checks covering the requested services. A service request submitted by a case manager appears on a dashboard monitored by an Operation ID employee. The dashboard is simply a list of service requests placed by case managers working at different agencies. When a new service request appears on the dashboard, its arrival is first acknowledged by checking a checkbox on the request. This acknowledgment will be seen by the case manager who placed the request, informing him/her that Operation ID is aware of the request. The service request will next be used to generate a Service Ticket which will be printed and added to a collection of outstanding Service Tickets. When Service Tickets representing enough clients have been accumulated, the status of each represented client will be changed to BackOffice, indicating that the service requests have been passed to the back office at Operation ID for processing. The respective case managers will see this change in status for their clients. Processing a Service Ticket in the back office is exactly the same process that takes place in the same-day-service model. It involves using Quickbooks to cut checks for services specified by a Service Ticket and recording the check numbers in the corresponding client database entry in the Apricot database. This processing will be handled by an Operation ID volunteer, as is done in the same-day-service model. Once the check(s) have been cut for a client, the Operation ID employee monitoring the dashboard changes the client's status to Done indicating to the client's case manager that processing has completed and checks may be picked up at the Operation ID office. The checks will be released to a case manager as redemption of the corresponding Case Manager Voucher. The process of remote operation described above involves only the case manager and Operation ID personnel. A client works with his/her case manager to generate a service request and then waits for the checks to be picked up at Operation ID by the case manager. Unlike the same-day-service model, the client never appears at Operation ID. This will be especially important as long as the same-day-service operation remains shut down. The Remote Operation ID process clearly requires more time to complete than the same-day-service model. As a practical matter, a Case Manager Voucher will indicate a 30 day period of validity. This is actually a time limit on how long Operation ID is given to respond to the corresponding service request once it appears on the OPIDDaily dashboard. The dashboard list will be sorted in chronological order of service request expiration dates. A service request will automatically roll off the dashboard once its expiration date has passed.","title":"Remote Operation ID"},{"location":"#service-history","text":"A Service Ticket lists not only the services a client is requesting but also the services the client has received in prior visits (if any). Listing previous services rendered is made possible by including a table of previously issued checks in the OPIDDaily database. Each record in the table of checks contains a check number, the check purpose, the name of the client to whom the check was issued and the disposition of the check, whether it was Cleared by the bank, Voided by the bank or one of several dispositions private to Operation ID. A check record does not include who the payee of the check is or the amount of the check. The check is referenced to the Apricot database simply by its unique number, not by the name of the client to whom the check was given. Periodically a pair of back office reports is processed by OPIDDaily to update its table of checks with the bank declared disposition of checks. These reports are generated by Quickbooks. One report lists check numbers of Cleared checks and the other report lists check numbers of Voided checks. This updating of the OPIDDaily table of checks implies that check numbers are recorded in the OPIDDaily database before their dispositions are known. This is indeed the case. To effect this, a report is periodically exported from the Apricot database and processed by OPIDDaily to import issued check into the OPIDDaily table of checks. By consulting the table of checks in the OPIDDaily database, it is possible to produce a service history for a client. A client with a service history is referred to as an Existing Client and a client with no previous service history is referred to as an Express Client. The term express client was chosen to imply that such a client's service request would be both easier and faster to process in the historic same-day-service model. As explained above, in practice a Service Ticket for an Express Client is not generated. In the remote operation model, a Service Ticket will be generated at Operation ID for both Existing Clients and Express Clients. Since there will be no referral letter under this model, the Service Ticket will be the only means of specifying requested services. Frequently a client will return to Operation ID requesting service before the disposition of a check previously issued to the client is known. In such a case, a back office volunteer will need to consult a Quickbooks ledger to determine the check's disposition. If the disposition can be determined, it may affect the service request by the client. In the same-day-service model, a client may need to be informed the he/she is not eligible for a requested service, because they have exhausted their twice-in-a-lifetime eligibility. This is sometimes a difficult conversation, especially if the client has endured a long line only to learn they are not eligible for the service they are requesting. In the remote operation model, Operation ID will convey ineligibility through the OPIDDaily website to a client's case manager. The case manager will then need to remind the client of the disclaimer about potential service denial that the client was made aware of when they signed their Case Manager Voucher.","title":"Service History"},{"location":"#this-document","text":"OPIDDaily is available as a password protected website to registered users. This document describes the design and implementation of OPIDDaily. The Infrastructure tab describes how project OPIDDaily is maintained on a desktop host and how it is deployed to the .NET hosting service AppHarbor. The Database tab describes how the OPIDDaily database is managed on the desktop and at AppHarbor. The Implementation tab provides some details concerning the implementation of OPIDDaily.","title":"This Document"},{"location":"Database/","text":"Database OPIDDaily is a database driven application built using SQL Server technology. In the desktop environment OPIDDaily is built using the Sql Server Express database engine. In the online environment at AppHarbor a full SQL Server is used. The two versions are compatible with each other with respect to the database features used. SQL Server Management Studio v18.0 (SSMS) is used to manage both database engines. In the desktop environment, Windows Authentication is used to connect to the Sql Server Express database. In the online enviroment, SQL Server Authentication is used to connect to the SQL Server database. When application OPIDDaily was created at AppHarbor, a free version of SQL Server was added on through the AppHarbor interface. The connection string to this SQL Server is found by selecting the SQL Server add-on and following the \"Go to SQL Server\" link on the page that appears. The value of this connection string is stored as the value of Config.WorkingProductionConnection string on file Config.cs. The 3 components of the connection string, HostName, UserName and Password, are also displayed on this page. The components may be used to configure a SQL Server Authentication connection to the AppHarbor database through SSMS. The same connection string displayed at AppHarbor is retrieved at runtime by accessing Config.ConnectionString, which returns the value of SQLSERVER_CONNNECTION_STRING configured in the <appSettings> section of file Web.config. The statically configured value on file Web.Config points to the OpidDailyDB on the desktop SQL Server Express. At runtime, AppHarbor will overwrite this statically configured value with the value displayed at AppHarbor. See the section on the Connection String on this tab. Connection String In the desktop environment, SSMS was used to create an empty project database by executing the SQL query create database OpidDailyDB The Visual Studio Server Explorer (found under the OPIDDaily project View menu) was then used to discover the connection string to database OpidDailyDB by creating a new Data Connection to it and copying the Connection String property of the data connection as the value of the variable SQLSERVER_CONNECTION_STRING in the <appSettings> section of Web.config. The value is accessed on files IDentityDB.cs and OpidDailyDB.cs by reading the value of the static variable Config.ConnectionString. The online version of OPIDDaily is hosted as an application at AppHarbor and it uses a database server provided as an add-on. The add-on database server includes a database which serves as the application database, so it is not necessary to create the application database as was done above for the desktop version. ELMAH uses the configuration string used by the OPIDDaily application. This is accomplished by configuring the connection string OpidDailyConnectionString in the <connectionStrings> section on Web.config and setting the connection string alias for the SQL Server add-on at AppHarbor to be OpidDailyConnectionString . To set this alias, select the SQL Server add-on for application OPIDDaily at AppHarbor and then follow the link \"Go to SQL Server\" on the page that appears. Click the button labeled \"Edit database configuration\" to set OpidDailyConnectionString as the alias value for the connection string. When this is done, OpidDailyConnectionString will appear as the value of SQLSERVER_CONNECTION_STRING_ALIAS in the Configuration variables section of application OPIDDaily at AppHarbor. When application OPIDDaily is deployed to AppHarbor, this alias will overwrite the configured value on file Web.config by the value of the connection string for the AppHarbor database. This is explained in the same knowledge base article referenced above. Database Diagram The diagram was created by SSMS, copied to the clipboard (using the \"Copy Diagram to Clipboard\" command found on the freespace context menu) and then pasted into the Paint tool. Inside of Paint it is saved as a .PNG file. Version 18.0 of SSMS does not allow database diagrams to be created. Newer releases have restored this capability. But the diagram seen here was created by an earlier release of SSMS, which did have the ability to create database diagrams. The 3 tables in the upper left of the above diagram are created by ASP.NET Identity 2.0 to manage registered users of OPIDDaily. The 3 tables are managed by their own data context which cannot be augmented by additional tables. However, data fields can be added to table AspNetUsers if necessary. The data field AgencyId was added to table AspNetUsers to store the unique AgencyId stored in table Agencies by the Superadmin user. (The AgencyId of an Operation ID user - example the TicketMaster user - is always 0.) Non ASP.NET Identity tables in the diagram are managed by a separate data context. The 2 data contexts of project OPIDDaily are referred to as IdentityDb and OpidDailyDB. (See the section Entity Framework Code First of the Infrastructure tab.) The technique for establishing a single connection string over 2 data contexts is described in Scott Allen's Pluralsight video . The tables belonging to data context OpidDailyDB were created at AppHarbor using a script file. This was done by running the command PM> update-database -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration -Script -SourceMigration $InitialDatabase to generate a SQL script to be run in SSMS against the database at AppHarbor. The command created a script file necessary to create the tables for this data context using all the migrations applied since the initial migration. Notice that there is no colon (:) following -SourceMigration in this command. To generate a script to run the Down methods of multiple down-migrations, do, for example, PM> Update-Database -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration -Script -TargetMigration: ExpressClient Notice that there is a colon (:) following -TargetMigration in this command. This command will create a script to execute in SSMS the Down methods of all migrations since (and not including) migration ExpressClient. It is important to be able to generate this script if changes need to be backed out, because the deployed versions of application OPIDDaily do not use Entity Framework to manage the database. After the script to run the Down method has been run in SSMS, delete the reverted migration from the set of migrations maintained for the data context in Visual Studio. Database Duplicates There are still many duplicates in the Apricot database as a result of the initial build from the legacy Access database. As an example, there are two records for the client John Harmon, DOB 9/11/1983: John Harmon, Record ID: 271978 John Marshall Harmon, Record ID: 4299 Since Service Tickets are built based on last name and DOB, both records will be used in building the Service Ticket for John Harmon. This can cause some confusion! Duplicate records are merged when they are discovered. The records for John Harmon may have been merged when the reader reads this documentation. Managing Users OPIDDaily is a role based database application administered by a Superadmin user. The Superadmin user has the responsibilty of establishing a login account for each OPIDDaily user, which includes the use's role. This is done prevent a user from specifying his/her own role when logging in and to force the user into his/her assigned role instead. See the introduction and Role Controllers sections of the Impementation tab for a discussion of roles. The Superadmin will be given a user name and email address for a new user. For example, if Mary Atwood would like to use the user name Mary and email address maryatwood@gmail.com, this request would be given to the Superadmin user. Provided that the user name Mary is not already in use, the Superadmin user would use a private interface to enter Mary Atwood in the Invitations table under UserName Mary (with FullName Mary Atwood) and Email Address maryatwood@gmail.com. The Superadmin would also use the OPIDDaily interface to assign a role to user Mary Atwood in the Invitations table. The record in the Invitations table is in effect an invitation for Mary Atwood to register under user name Mary and email address maryatwood@gmail.com in the assigned role. The Superadmin will notify Mary that her account has been created and that she may register with application OPIDDaily using the credentials she has supplied together with a password of her own choosing. When Mary registers, the user name and email address she provides will be checked against the Invitations table. If this pair of credentials is not found in the Invitations table, Mary's attempt to register will be rejected. If they are found, a record will be created for her in the AspNetUsers table using the password she has specified and using the role assigned by the Superadmin, which has been stored in the Invitations table. On subsequent visits to OPIDDaily, Mary may simply login with the credentials established by her registration. When logged in she will be recognized in her assigned role. User email addresses do not need to be unique per account. This is not the default behavior; it is enabled by the setting RequireUniqueEmail = false in method ApplicationUserManager.Create on file App_Start/IdentityConfig.cs There are two special accounts reserved for usage by the two users who serve at the front desk on any given day of operation. Each of these accounts has the pre-assigned role called FrontDesk. The users are the Screener and the TicketMaster which correspond to the pipeline stages Screening and Checkin , respectively. (See the Background tab for information about the pipeline stages.) Having dedicated accounts avoids the need to create unique accounts in the role of FrontDesk. There are also two additional special users called Client1 and Client2 corresponding to the pipeline stages Screening and CheckIn , respectively. (See the Background tab for information about the pipeline stages.) During the screening stage, the Screener user will enter the name and date of birth of an entering client into the OPIDDaily database. To ensure that this information has been correctly entered, the Screener may click a button to have this information appear on a small tablet computer which will be handed to the client for verification. This small tablet computer will be logged into the OPIDDaily application as Client1 . During the Checkin stage, by consultng the Apricot database, the TicketMaster user will record any previous visit history by a screened client in the OPIDDaily database. If previous visits indicate that the screened client is ineligible for a service being sought, the TicketMaster may click a button to have the visit history appear on a second small tablet computer which will be handed to the client. This second small tablet computer will be logged into the OPIDDaily application as Client2 . Both users Client1 and Client2 are assigned the role FrontDesk. Database Utilization AppHarbor allows 20MB of database storage with the free SQL Server. The current utilization can be checked at AppHarbor by selecting the SQL Server used by application OPIDDaily and following the \"Go to server\" link. As of February 8, 2020 10.2MB out of the free 20MB are in use. This database contains 32,500 checks which were cut since 2013. Of these, between 24,00 and 28,000 checks were cut over the past 4 years. This suggests that there is enough capacity in the free database to run for at least 3 more years before approaching the 20MB limit. The disk utilization should be monitored periodically to make sure the limit is not exceeded. Currently an upgrade to 10GB of space would cost $10/month. This should be an affordable expense when the time comes that the additional space is needed. SSMS can be used to check on the utilization of a database. To do so: Right click a database name Navigate to Reports > Standard Reports > Disk Usage Navigate to Reports > Standard Reports > Disk Usage By Table Although this can be done, the single number reported by AppHarbor is easier to understand. Rebuilding the Research Table In February 2020 application OPIDChecks was merged into application OPIDDaily for the sake of having a single application that performs both functions. The merge required the Research Table to be added to application OPIDDaily. The merger of the two applications had the additional benefit of allowing application OPIDDaily to use the Research Table to populate the \"visit history\" of clients with previous visits. The Research Table was rebuilt by loading files created by two different reports in Apricot: Bounded Research Report was used to create files: Bounded Research Table 2017 Bounded Research Table 2018 Bounded Research Table 2019 Bounded Research Table 2020 Imported from Access DB was used to create files: Imported from Access DB 2010 Imported from Access DB 2011 Imported from Access DB 2012 Imported from Access DB 2013 Imported from Access DB 2014 Imported from Access DB 2015 Imported from Access DB 2016 With the exception of files Imported from Access DB 2010 Imported from Access DB 2011 Imported from Access DB 2012 which contain very little (and incomplete) data these files were loaded to rebuild the Research Table. This was a one time rebuild of the Research Table at AppHarbor. As the Research Table became large it as necessary to split Files of import data containing a year's worth of data into multiple files to allow the import to be processed. If the amount of data in a given file was still too much, a 504 Gateway Timeout Error was generated. When this happened, a new instance of OPID Daily was opened. The new instance would resume loading until completion. The second instance did not generate a gateway timeout error. Moving forward, if the Research Table becomes corrupt, then it can be rebuilt from scratch by regenerating and rerunning these reports. Rebuilding the Research Table from scratch takes several hours. A rebuilt Research Table should not be used for 24 hours to allow for indexes to be built. Until the indexes have been built, searching the Research Table will be sluggish. AppHarbor does not perform a daily backup on a free SQL Server. It is necessary to step up to a dedicated SQL Server to receive daily backups. The cheapest dedicated SQL Server offers 100GB of storage space at a cost of $200/month. Either the free SQL Server or the upgrade to 10GB of storage at $10/month seems preferable. However, it is necessary to keep the Research Table updated. This is done on a weekly basis by running the Apricot report called OPID Daily and providing the date of the Monday beginning a week of operation after the week is complete. For example the OPID Daily report should be run using Monday February 10, 2020 as the filter date on any day following Thursday February 13, 2020. This will create a file containing all the records modified during the week starting on Monday February 10. If this file is created on Monday February 17, then it should be renamed as: OPIDDaily 02172020. By merging the renamed file into application OPIDDaily, the Research Table will be brought up to date.","title":"Database"},{"location":"Database/#database","text":"OPIDDaily is a database driven application built using SQL Server technology. In the desktop environment OPIDDaily is built using the Sql Server Express database engine. In the online environment at AppHarbor a full SQL Server is used. The two versions are compatible with each other with respect to the database features used. SQL Server Management Studio v18.0 (SSMS) is used to manage both database engines. In the desktop environment, Windows Authentication is used to connect to the Sql Server Express database. In the online enviroment, SQL Server Authentication is used to connect to the SQL Server database. When application OPIDDaily was created at AppHarbor, a free version of SQL Server was added on through the AppHarbor interface. The connection string to this SQL Server is found by selecting the SQL Server add-on and following the \"Go to SQL Server\" link on the page that appears. The value of this connection string is stored as the value of Config.WorkingProductionConnection string on file Config.cs. The 3 components of the connection string, HostName, UserName and Password, are also displayed on this page. The components may be used to configure a SQL Server Authentication connection to the AppHarbor database through SSMS. The same connection string displayed at AppHarbor is retrieved at runtime by accessing Config.ConnectionString, which returns the value of SQLSERVER_CONNNECTION_STRING configured in the <appSettings> section of file Web.config. The statically configured value on file Web.Config points to the OpidDailyDB on the desktop SQL Server Express. At runtime, AppHarbor will overwrite this statically configured value with the value displayed at AppHarbor. See the section on the Connection String on this tab.","title":"Database"},{"location":"Database/#connection-string","text":"In the desktop environment, SSMS was used to create an empty project database by executing the SQL query create database OpidDailyDB The Visual Studio Server Explorer (found under the OPIDDaily project View menu) was then used to discover the connection string to database OpidDailyDB by creating a new Data Connection to it and copying the Connection String property of the data connection as the value of the variable SQLSERVER_CONNECTION_STRING in the <appSettings> section of Web.config. The value is accessed on files IDentityDB.cs and OpidDailyDB.cs by reading the value of the static variable Config.ConnectionString. The online version of OPIDDaily is hosted as an application at AppHarbor and it uses a database server provided as an add-on. The add-on database server includes a database which serves as the application database, so it is not necessary to create the application database as was done above for the desktop version. ELMAH uses the configuration string used by the OPIDDaily application. This is accomplished by configuring the connection string OpidDailyConnectionString in the <connectionStrings> section on Web.config and setting the connection string alias for the SQL Server add-on at AppHarbor to be OpidDailyConnectionString . To set this alias, select the SQL Server add-on for application OPIDDaily at AppHarbor and then follow the link \"Go to SQL Server\" on the page that appears. Click the button labeled \"Edit database configuration\" to set OpidDailyConnectionString as the alias value for the connection string. When this is done, OpidDailyConnectionString will appear as the value of SQLSERVER_CONNECTION_STRING_ALIAS in the Configuration variables section of application OPIDDaily at AppHarbor. When application OPIDDaily is deployed to AppHarbor, this alias will overwrite the configured value on file Web.config by the value of the connection string for the AppHarbor database. This is explained in the same knowledge base article referenced above.","title":"Connection String"},{"location":"Database/#database-diagram","text":"The diagram was created by SSMS, copied to the clipboard (using the \"Copy Diagram to Clipboard\" command found on the freespace context menu) and then pasted into the Paint tool. Inside of Paint it is saved as a .PNG file. Version 18.0 of SSMS does not allow database diagrams to be created. Newer releases have restored this capability. But the diagram seen here was created by an earlier release of SSMS, which did have the ability to create database diagrams. The 3 tables in the upper left of the above diagram are created by ASP.NET Identity 2.0 to manage registered users of OPIDDaily. The 3 tables are managed by their own data context which cannot be augmented by additional tables. However, data fields can be added to table AspNetUsers if necessary. The data field AgencyId was added to table AspNetUsers to store the unique AgencyId stored in table Agencies by the Superadmin user. (The AgencyId of an Operation ID user - example the TicketMaster user - is always 0.) Non ASP.NET Identity tables in the diagram are managed by a separate data context. The 2 data contexts of project OPIDDaily are referred to as IdentityDb and OpidDailyDB. (See the section Entity Framework Code First of the Infrastructure tab.) The technique for establishing a single connection string over 2 data contexts is described in Scott Allen's Pluralsight video . The tables belonging to data context OpidDailyDB were created at AppHarbor using a script file. This was done by running the command PM> update-database -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration -Script -SourceMigration $InitialDatabase to generate a SQL script to be run in SSMS against the database at AppHarbor. The command created a script file necessary to create the tables for this data context using all the migrations applied since the initial migration. Notice that there is no colon (:) following -SourceMigration in this command. To generate a script to run the Down methods of multiple down-migrations, do, for example, PM> Update-Database -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration -Script -TargetMigration: ExpressClient Notice that there is a colon (:) following -TargetMigration in this command. This command will create a script to execute in SSMS the Down methods of all migrations since (and not including) migration ExpressClient. It is important to be able to generate this script if changes need to be backed out, because the deployed versions of application OPIDDaily do not use Entity Framework to manage the database. After the script to run the Down method has been run in SSMS, delete the reverted migration from the set of migrations maintained for the data context in Visual Studio.","title":"Database Diagram"},{"location":"Database/#database-duplicates","text":"There are still many duplicates in the Apricot database as a result of the initial build from the legacy Access database. As an example, there are two records for the client John Harmon, DOB 9/11/1983: John Harmon, Record ID: 271978 John Marshall Harmon, Record ID: 4299 Since Service Tickets are built based on last name and DOB, both records will be used in building the Service Ticket for John Harmon. This can cause some confusion! Duplicate records are merged when they are discovered. The records for John Harmon may have been merged when the reader reads this documentation.","title":"Database Duplicates"},{"location":"Database/#managing-users","text":"OPIDDaily is a role based database application administered by a Superadmin user. The Superadmin user has the responsibilty of establishing a login account for each OPIDDaily user, which includes the use's role. This is done prevent a user from specifying his/her own role when logging in and to force the user into his/her assigned role instead. See the introduction and Role Controllers sections of the Impementation tab for a discussion of roles. The Superadmin will be given a user name and email address for a new user. For example, if Mary Atwood would like to use the user name Mary and email address maryatwood@gmail.com, this request would be given to the Superadmin user. Provided that the user name Mary is not already in use, the Superadmin user would use a private interface to enter Mary Atwood in the Invitations table under UserName Mary (with FullName Mary Atwood) and Email Address maryatwood@gmail.com. The Superadmin would also use the OPIDDaily interface to assign a role to user Mary Atwood in the Invitations table. The record in the Invitations table is in effect an invitation for Mary Atwood to register under user name Mary and email address maryatwood@gmail.com in the assigned role. The Superadmin will notify Mary that her account has been created and that she may register with application OPIDDaily using the credentials she has supplied together with a password of her own choosing. When Mary registers, the user name and email address she provides will be checked against the Invitations table. If this pair of credentials is not found in the Invitations table, Mary's attempt to register will be rejected. If they are found, a record will be created for her in the AspNetUsers table using the password she has specified and using the role assigned by the Superadmin, which has been stored in the Invitations table. On subsequent visits to OPIDDaily, Mary may simply login with the credentials established by her registration. When logged in she will be recognized in her assigned role. User email addresses do not need to be unique per account. This is not the default behavior; it is enabled by the setting RequireUniqueEmail = false in method ApplicationUserManager.Create on file App_Start/IdentityConfig.cs There are two special accounts reserved for usage by the two users who serve at the front desk on any given day of operation. Each of these accounts has the pre-assigned role called FrontDesk. The users are the Screener and the TicketMaster which correspond to the pipeline stages Screening and Checkin , respectively. (See the Background tab for information about the pipeline stages.) Having dedicated accounts avoids the need to create unique accounts in the role of FrontDesk. There are also two additional special users called Client1 and Client2 corresponding to the pipeline stages Screening and CheckIn , respectively. (See the Background tab for information about the pipeline stages.) During the screening stage, the Screener user will enter the name and date of birth of an entering client into the OPIDDaily database. To ensure that this information has been correctly entered, the Screener may click a button to have this information appear on a small tablet computer which will be handed to the client for verification. This small tablet computer will be logged into the OPIDDaily application as Client1 . During the Checkin stage, by consultng the Apricot database, the TicketMaster user will record any previous visit history by a screened client in the OPIDDaily database. If previous visits indicate that the screened client is ineligible for a service being sought, the TicketMaster may click a button to have the visit history appear on a second small tablet computer which will be handed to the client. This second small tablet computer will be logged into the OPIDDaily application as Client2 . Both users Client1 and Client2 are assigned the role FrontDesk.","title":"Managing Users"},{"location":"Database/#database-utilization","text":"AppHarbor allows 20MB of database storage with the free SQL Server. The current utilization can be checked at AppHarbor by selecting the SQL Server used by application OPIDDaily and following the \"Go to server\" link. As of February 8, 2020 10.2MB out of the free 20MB are in use. This database contains 32,500 checks which were cut since 2013. Of these, between 24,00 and 28,000 checks were cut over the past 4 years. This suggests that there is enough capacity in the free database to run for at least 3 more years before approaching the 20MB limit. The disk utilization should be monitored periodically to make sure the limit is not exceeded. Currently an upgrade to 10GB of space would cost $10/month. This should be an affordable expense when the time comes that the additional space is needed. SSMS can be used to check on the utilization of a database. To do so: Right click a database name Navigate to Reports > Standard Reports > Disk Usage Navigate to Reports > Standard Reports > Disk Usage By Table Although this can be done, the single number reported by AppHarbor is easier to understand.","title":"Database Utilization"},{"location":"Database/#rebuilding-the-research-table","text":"In February 2020 application OPIDChecks was merged into application OPIDDaily for the sake of having a single application that performs both functions. The merge required the Research Table to be added to application OPIDDaily. The merger of the two applications had the additional benefit of allowing application OPIDDaily to use the Research Table to populate the \"visit history\" of clients with previous visits. The Research Table was rebuilt by loading files created by two different reports in Apricot: Bounded Research Report was used to create files: Bounded Research Table 2017 Bounded Research Table 2018 Bounded Research Table 2019 Bounded Research Table 2020 Imported from Access DB was used to create files: Imported from Access DB 2010 Imported from Access DB 2011 Imported from Access DB 2012 Imported from Access DB 2013 Imported from Access DB 2014 Imported from Access DB 2015 Imported from Access DB 2016 With the exception of files Imported from Access DB 2010 Imported from Access DB 2011 Imported from Access DB 2012 which contain very little (and incomplete) data these files were loaded to rebuild the Research Table. This was a one time rebuild of the Research Table at AppHarbor. As the Research Table became large it as necessary to split Files of import data containing a year's worth of data into multiple files to allow the import to be processed. If the amount of data in a given file was still too much, a 504 Gateway Timeout Error was generated. When this happened, a new instance of OPID Daily was opened. The new instance would resume loading until completion. The second instance did not generate a gateway timeout error. Moving forward, if the Research Table becomes corrupt, then it can be rebuilt from scratch by regenerating and rerunning these reports. Rebuilding the Research Table from scratch takes several hours. A rebuilt Research Table should not be used for 24 hours to allow for indexes to be built. Until the indexes have been built, searching the Research Table will be sluggish. AppHarbor does not perform a daily backup on a free SQL Server. It is necessary to step up to a dedicated SQL Server to receive daily backups. The cheapest dedicated SQL Server offers 100GB of storage space at a cost of $200/month. Either the free SQL Server or the upgrade to 10GB of storage at $10/month seems preferable. However, it is necessary to keep the Research Table updated. This is done on a weekly basis by running the Apricot report called OPID Daily and providing the date of the Monday beginning a week of operation after the week is complete. For example the OPID Daily report should be run using Monday February 10, 2020 as the filter date on any day following Thursday February 13, 2020. This will create a file containing all the records modified during the week starting on Monday February 10. If this file is created on Monday February 17, then it should be renamed as: OPIDDaily 02172020. By merging the renamed file into application OPIDDaily, the Research Table will be brought up to date.","title":"Rebuilding the Research Table"},{"location":"Implementation/","text":"Implementation Application OPIDDaily is implemented as an ASP.NET Framework application using the ASP.NET MVC 5 project template provided by Visual Studio 2019 (Community Edition). It uses ASP.NET Identity 2.0 to define a set of user roles. Each user role is associated with a separate MVC controller. Controller inheritance is used to share editing functionality across user roles. It may be useful to upgrade application OPIDDaily to use the more modern ASP.NET Core technology. It may also be useful to provide an alternative to the free hosting service AppHarbor, which is currently used by OPIDDaily. See the AppHarbor section of the Infrastructure tab for details on this. The graphical user interface of OPIDDaily is built using Bootstrap 3.0.0. Each user role is associated with its own layout file which defines a Bootstrap navbar containing links to the OPIDDaily features available to users in the role. The ASP.NET Identity system ensures that a user in a specified role cannot visit any pages outside of those allowed to users in that role. (See the section on Role Controllers.) Because of its use of SignalR, application OPIDDaily will always require a server side component. See the section on SignalR on this tab for a discussion of this. Users OPIDDaily is a role-based system. Each registered user will be assigned a user role by the OPIDDaily administrator. The role that a user is assigned will determine the OPIDDaily features available to the user. A user's assigned role will depend upon whether the user volunteers at the front desk, is a volunteer interviewer or is a back office volunteer. In addition, there will be a manager's role to be assigned to Operation ID managers who want to watch the client processing flow during a day of operation. The OPIDDaily administrator will be in the role of Superadmin and will have access to features necessary for the maintenance of application OPIDDaily. There will be only one Superadmin account, but the credentials for this account will be available to maintainers of the application. The Superadmin User OPIDDaily defines a pre-registered Superadmin user who has privileges to create new roles invite new users to register in a pre-determined role add new agencies The credentials for the Superadmin user are configured on file Startup.cs. There is only a single user with role of Superadmin. MVC Routing Application OPIDDaily uses only the default routing rule supplied by the Visual Studio MVC 5 template. This default routing rule is found in .../App_Start/RouteConfig.cs . routes.MapRoute( name: \"Default\", url: \"{controller}/{action}/{id}\", defaults: new { controller = \"Users\", action = \"Index\", id = UrlParameter.Optional } ); For the sake of simplicity, future development of application OPIDDaily should strive to keep this as the one and only routing rule. Role Controllers There is an MVC controller defined for each role defined by the superadmin user. Each controller defined for a role inherits from SharedController to implement shared functionality. The role controllers manage the views of application OPIDDaily. The implementation of each role controller defines methods that are accessible through the menubar defined on the layout file for the role. For example, the FrontDeskController - which implements the FrontDesk role - contains methods ExpressClient and ExistingClient (found on the SharedController) invoked from the menubar defined on file ~/Shared/_FrontDesk.cshtml. This is the layout file for the FrontDesk role. Each view returned by the FrontDeskController includes this layout file, thereby ensuring that a user in the role of FrontDesk will only invoke methods defined by the FrontDeskController. Each other role controllers is implemented the same way: each has a defined layout file that is included in each view returned by the controller. The layout file defines a menubar that specifies the methods that users in the role can invoke. As protection against unauthorized access to methods of a role controller, use of each role controller is limited to users in the role associated with the controller. For example, the FrontDeskController is protected by the annotation [Authorize(Roles = \"FrontDesk\")] Access is then restricted by the functionality of ASP.NET Identity to authenticated users in role FrontDesk. The SharedController Each role controller derives from SharedController. The SharedController implements the shared editor functionality available to the different roles. Deriving role controllers from a shared controller is an extremely useful technique for building a role-based editor. The UsersController The UsersController controls access to the ASP.NET Identity tables used to store registered users and the roles they are in. The method UsersController.Index is the entry point for an authenticated user. The role an authenticated user is in determines the method the user will be redirected to from this entry point. jqGrid The entire implementation of application OPIDDaily is structured around instances of jqGrid appearing in MVC Views. Each jqGrid is initially populated by a call to an MVC action made through the url property of the grid. For example, the clientsGrid on view FrontDesk/Clients.cshtml is initially populated by the call \"@Url.Action(\"GetClients\", \"FrontDesk)\" which is the value of the url argument to grid clientsGrid. (Method GetClients is found on the SharedController.) Each instance of a jqGride defines a pager , which defines the CRUD operations supported by the grid. Each CRUD operation is implemented by an MVC action of the role controller associated with the grid. Initial population of a grid, grid pagination, grid searching and grid CRUD operations are all supported by server side code. There is a collection of jqGrid Demos that was very helpful during the development of OPIDDaily. jquery Datatables The Research Table is implemented as a server-side datatable. It is dependent on 2 packages from NuGet: jquery.datatables v1.10.15 datatables.mvc5 v0.1.0 The first of the 2 packages adds folders: ~/Content/DataTables ~/Scripts/DataTables The packages should be loaded in the given order. NowServing By convention, wherever the code makes use of a variable with the name nowServing, its value is the id of a client that has been selected from a jqGrid. Understanding this convention greatly simplifies understanding the code base. For example, when a row in the clientsGrid defined on FrontDeskClients.cshtml is selected, the JavaScript function that is the value of the onSelectRow property of the grid is invoked. When the function is invoked, the value passed to its nowServing argument is the id associated with the client represented by the selected row. The function posts to the server side method NowServing of the FrontDeskController (found on SharedController) via the code Url.Action(\"NowServing\", \"FrontDesk\") passing the JavaScript variable nowServing in the post as a result of the line postData: { nowServing: nowServing } Method SharedController/NowServing has an optional argument called nowServing. MVC data binding will cause this variable to be bound to the JavaScript variable in the post. Households Table Clients is a list of clients and their dependents. Most clients represent only themselves but some have dependents. A client together with any dependents he or she may have is referred to as a household . The head of a household is a top level member of the table Clients . The HH field of each top level client C is set to 0, that is C.HH = 0. If client D is a dependent of client C then the HH field of client D points back to client C through the setting D.HH = C.Id. In fact, dependent D belongs to a subgrid of the jqGrid used to render the Clients table. Dependent D is added to the subgrid whose parent entry is the entry for client C. If client C is has dependents, then C.HeadOfHousehold will be set to true and the row rendering client C in the jqGrid will indicate that client C is the head of a household. The AgencyId Data Field in table AspNetUsers Application OPIDDaily is used by users at Operation ID and by users representing agencies that refer clients to Operation ID. The AgencyId field in table AspNetUsrs will be set to 0 for Operation ID users (for example the TicketMaster user) and will be set to the AgencyId of their referring agency for other users. The AgencyId data field in the Clients table is set in the same way. So, the AgencyId of a client entered into the Clients table at Operation ID on a day of operation will be set to 0. The AgencyId of a client entered by a user representing a referring agency will be set to the AgencyId of the referring agency. Clients are tagged in this way to allow Operation ID users to see all clients and to allow a users from a referring agency to see only the clients referred by that agency. Date management Dates are treated differently at AppHarbor from the way they are treated on the desktop. In both environments, a date is stored as the midnight hour. For example, March 26, 2020 is stored as 2020-03-26:00:00:00:000 in the desktop database as well as in the AppHarbor database. But if this date is stored in a ClientViewModel object and reported as the value of a jqGrid column using the date formatter, then the desktop reports it as 03/26/2020 whereas AppHarbor reports it as 03/25/2020. It is not clear why this happens, but a way to make both environments report 03/26/2020 is to offset the value stored in the view model by 12 hours to noon (2020-03-26:12:00:00:000). This is for done several DateTime data fields in Clients.ClientEntityToClientViewModel. (A 1 hour offset was tried first, but it did not work.) The same 12 hour offsetting was done with the Date field in a VisitViewModel. This can be found on file DAL/Visits.cs. When a jqGrid row containing a date is edited the date posted to the server is the midnight time, not the offset to noon time. When the row is retrieved in a ClientViewModel, the time will again be offset by 12 hour to noon and will thus display as intended in the jqGrid. The ServiceDate and Expiry data fields in Table Clients When the TicketMaster adds a new client to the Clients* table the date the client is entered is recorded in the ServiceDate data field of table Clients . The same date is recorded in the Expiry data field. When a Case Manager user enters a new client into the Clients table, the ServiceDate data field is set to the date the client is entered, but the Expiry data field is set at least 30 days into the future. This expiry date will be printed on the Case Manager Voucher given to a client by his/her Case Manager. Application OPIDDaily will preload the Clients** table seen by the TicketMaster with any clients whose Expiry date has not yet past. This will allow a client entered by a Case Manager to be given priority service on the day he/she appears at Operation ID. It is the client's responsibility to appear at Operation ID on or before the expiry date printed on his/her voucher. SessionHelper The SessionHelper class found on fie DAL/SessionHelper.cs is the key method for managing state in application OPIDDaily. This class is used to store key value pairs in the sesssion context private to each authenticated user. Managing the value of NowServing is a key use of the SessionHelper. Instead of having methods called GetNowServing and SetNowServing, the SharedController uses polymorphism to define two methods called NowServing with different signatures. The NowServing method with zero arguments invokes method SessionHelper.Get and the NowServing method with optional argumnt nowServing invokes method SessionHelper.Set. These two NowServing methods are invoked by many methods on SharedController to implement editing functionality private to an authenticated user. Express Clients and Existing Clients A first time client to Operation ID is referred to as an Express Client. Determining whether a given client is an Express Client is done by consulting the Apricot database to determine whether the client has a visit history . A visit history is a list of services previously performed for a client. If a client is determined to be an Express Client, then a user in the role FrontDesk (a FrontDesk admin) must use the OPIDDaily interface to edit the client and mark him/her as an Express Client. If consulting the Apricot database indicates that a client has a previous service history at Operation ID, then a FrontDesk admin must use the OPIDDaily interface to copy the history of previous visits to the Visits table. This table is related to the Clients table by a foreign key relationship. See the section Entity Framework Code First on the Infrastructure tab for a discussion of this foreign key relationship. Method AddClient of the SharedController receives the id returned by method Clients.AddVisit. This id will be the id of the client inserted into the Clients table. See this StackOverflow article for an explantion of the side effect of record insertion relied upon for this. The client with this id will become the NowServing client. (See the section NowServing.) The foreign key relationship existing between tables Clients and Visits is not supported by a cascading delete; deleting a client from the Clients table does not by default perform a cascading delete of any related records in the Visits table. The cascading delete must be performed manually. To see how this is done, see method RemoveClients in the SuperadminController. A client not marked as an Express Client is referred to as an Existing Client. A FrontDesk admin is responsible for using the interface to distinguish between these two types of client. This has the advantage that a user in the role of Interviewer (an Interviewer admin) need not know the difference. An Interviewer admin prepares Service Tickets (see next section) which automatically include the service history which has been recorded by a FrontDesk admin for Existing Clients. Service Tickets A primary goal of application OPIDDaily is the production of Service Tickets . A service ticket is a single piece of paper that shows the services requested by a given client together with the documents the client is supplying in support of his/her service request. In addition a service ticket provides a history of service requests from previous visits by the client, if any. Service Tickets are produced by an Interviewer Admin. The interviewing process begins by determining the service needs of a client together with documents the client is supplying in support of those needs. An Interviewer admin will use the OPIDDaily interface to capture this information. A client's history of previous visits to Operation ID will have already been recorded by a FrontDesk admin by consulting the Apricot database. After the Service Ticket for a client has been produced, an Interviewer admin will assist the client in filling out paperwork in support of service sought. It is suggested that a client's Service Ticket be forwarded to a BackOffice admin before work on a client's paperwork begins. By passing the Service Ticket to a BackOffice admin, a client's service voucher(s) can be cut and recorded in Apricot while the client is busy with paperwork. In effect a client's BackOffice stage can proceed in parallel with his/her Interviewing stage once the Service Ticket has been produced. SignalR Application OIDDaily uses version 2.4.1 of the JavaScript SignalR package installed via NuGet. SignalR is a push-technology used to inform authenticated users about the progress of an Operation ID client as he/she passes through the Operation ID pipeline. The SignalR connection hub is defined on file DAL/DailyHub.cs. Invoking a method of DailyHub in the server side code causes a push-notification to go out to all clients registered to the hub. For example, when a FrontDesk admin adds a new client to the jqGrid managed by the FrontDeskController, the method SharedController.AddClient will invoke DailyHub.Refresh. A call to the line hubContext.Clients.All.refreshPage(); will send a push notification to all registered clients of the hub. Those clients listening for this notification, for example the view Interviewer/Clients.cshtml, will act upon the notification. In this case, the action will be to refresh the jqGrid of clients displayed by the grid. In this way this grid is kept in synch with the grid to which the client was added by the FrontDesk admin. SignalR is also used by both the special users Client1 and Client2 to refresh the tablet computer displays used by these users. (See the section Managing Users on the Database tab.)","title":"Implementation"},{"location":"Implementation/#implementation","text":"Application OPIDDaily is implemented as an ASP.NET Framework application using the ASP.NET MVC 5 project template provided by Visual Studio 2019 (Community Edition). It uses ASP.NET Identity 2.0 to define a set of user roles. Each user role is associated with a separate MVC controller. Controller inheritance is used to share editing functionality across user roles. It may be useful to upgrade application OPIDDaily to use the more modern ASP.NET Core technology. It may also be useful to provide an alternative to the free hosting service AppHarbor, which is currently used by OPIDDaily. See the AppHarbor section of the Infrastructure tab for details on this. The graphical user interface of OPIDDaily is built using Bootstrap 3.0.0. Each user role is associated with its own layout file which defines a Bootstrap navbar containing links to the OPIDDaily features available to users in the role. The ASP.NET Identity system ensures that a user in a specified role cannot visit any pages outside of those allowed to users in that role. (See the section on Role Controllers.) Because of its use of SignalR, application OPIDDaily will always require a server side component. See the section on SignalR on this tab for a discussion of this.","title":"Implementation"},{"location":"Implementation/#users","text":"OPIDDaily is a role-based system. Each registered user will be assigned a user role by the OPIDDaily administrator. The role that a user is assigned will determine the OPIDDaily features available to the user. A user's assigned role will depend upon whether the user volunteers at the front desk, is a volunteer interviewer or is a back office volunteer. In addition, there will be a manager's role to be assigned to Operation ID managers who want to watch the client processing flow during a day of operation. The OPIDDaily administrator will be in the role of Superadmin and will have access to features necessary for the maintenance of application OPIDDaily. There will be only one Superadmin account, but the credentials for this account will be available to maintainers of the application.","title":"Users"},{"location":"Implementation/#the-superadmin-user","text":"OPIDDaily defines a pre-registered Superadmin user who has privileges to create new roles invite new users to register in a pre-determined role add new agencies The credentials for the Superadmin user are configured on file Startup.cs. There is only a single user with role of Superadmin.","title":"The Superadmin User"},{"location":"Implementation/#mvc-routing","text":"Application OPIDDaily uses only the default routing rule supplied by the Visual Studio MVC 5 template. This default routing rule is found in .../App_Start/RouteConfig.cs . routes.MapRoute( name: \"Default\", url: \"{controller}/{action}/{id}\", defaults: new { controller = \"Users\", action = \"Index\", id = UrlParameter.Optional } ); For the sake of simplicity, future development of application OPIDDaily should strive to keep this as the one and only routing rule.","title":"MVC Routing"},{"location":"Implementation/#role-controllers","text":"There is an MVC controller defined for each role defined by the superadmin user. Each controller defined for a role inherits from SharedController to implement shared functionality. The role controllers manage the views of application OPIDDaily. The implementation of each role controller defines methods that are accessible through the menubar defined on the layout file for the role. For example, the FrontDeskController - which implements the FrontDesk role - contains methods ExpressClient and ExistingClient (found on the SharedController) invoked from the menubar defined on file ~/Shared/_FrontDesk.cshtml. This is the layout file for the FrontDesk role. Each view returned by the FrontDeskController includes this layout file, thereby ensuring that a user in the role of FrontDesk will only invoke methods defined by the FrontDeskController. Each other role controllers is implemented the same way: each has a defined layout file that is included in each view returned by the controller. The layout file defines a menubar that specifies the methods that users in the role can invoke. As protection against unauthorized access to methods of a role controller, use of each role controller is limited to users in the role associated with the controller. For example, the FrontDeskController is protected by the annotation [Authorize(Roles = \"FrontDesk\")] Access is then restricted by the functionality of ASP.NET Identity to authenticated users in role FrontDesk.","title":"Role Controllers"},{"location":"Implementation/#the-sharedcontroller","text":"Each role controller derives from SharedController. The SharedController implements the shared editor functionality available to the different roles. Deriving role controllers from a shared controller is an extremely useful technique for building a role-based editor.","title":"The SharedController"},{"location":"Implementation/#the-userscontroller","text":"The UsersController controls access to the ASP.NET Identity tables used to store registered users and the roles they are in. The method UsersController.Index is the entry point for an authenticated user. The role an authenticated user is in determines the method the user will be redirected to from this entry point.","title":"The UsersController"},{"location":"Implementation/#jqgrid","text":"The entire implementation of application OPIDDaily is structured around instances of jqGrid appearing in MVC Views. Each jqGrid is initially populated by a call to an MVC action made through the url property of the grid. For example, the clientsGrid on view FrontDesk/Clients.cshtml is initially populated by the call \"@Url.Action(\"GetClients\", \"FrontDesk)\" which is the value of the url argument to grid clientsGrid. (Method GetClients is found on the SharedController.) Each instance of a jqGride defines a pager , which defines the CRUD operations supported by the grid. Each CRUD operation is implemented by an MVC action of the role controller associated with the grid. Initial population of a grid, grid pagination, grid searching and grid CRUD operations are all supported by server side code. There is a collection of jqGrid Demos that was very helpful during the development of OPIDDaily.","title":"jqGrid"},{"location":"Implementation/#jquery-datatables","text":"The Research Table is implemented as a server-side datatable. It is dependent on 2 packages from NuGet: jquery.datatables v1.10.15 datatables.mvc5 v0.1.0 The first of the 2 packages adds folders: ~/Content/DataTables ~/Scripts/DataTables The packages should be loaded in the given order.","title":"jquery Datatables"},{"location":"Implementation/#nowserving","text":"By convention, wherever the code makes use of a variable with the name nowServing, its value is the id of a client that has been selected from a jqGrid. Understanding this convention greatly simplifies understanding the code base. For example, when a row in the clientsGrid defined on FrontDeskClients.cshtml is selected, the JavaScript function that is the value of the onSelectRow property of the grid is invoked. When the function is invoked, the value passed to its nowServing argument is the id associated with the client represented by the selected row. The function posts to the server side method NowServing of the FrontDeskController (found on SharedController) via the code Url.Action(\"NowServing\", \"FrontDesk\") passing the JavaScript variable nowServing in the post as a result of the line postData: { nowServing: nowServing } Method SharedController/NowServing has an optional argument called nowServing. MVC data binding will cause this variable to be bound to the JavaScript variable in the post.","title":"NowServing"},{"location":"Implementation/#households","text":"Table Clients is a list of clients and their dependents. Most clients represent only themselves but some have dependents. A client together with any dependents he or she may have is referred to as a household . The head of a household is a top level member of the table Clients . The HH field of each top level client C is set to 0, that is C.HH = 0. If client D is a dependent of client C then the HH field of client D points back to client C through the setting D.HH = C.Id. In fact, dependent D belongs to a subgrid of the jqGrid used to render the Clients table. Dependent D is added to the subgrid whose parent entry is the entry for client C. If client C is has dependents, then C.HeadOfHousehold will be set to true and the row rendering client C in the jqGrid will indicate that client C is the head of a household.","title":"Households"},{"location":"Implementation/#the-agencyid-data-field-in-table-aspnetusers","text":"Application OPIDDaily is used by users at Operation ID and by users representing agencies that refer clients to Operation ID. The AgencyId field in table AspNetUsrs will be set to 0 for Operation ID users (for example the TicketMaster user) and will be set to the AgencyId of their referring agency for other users. The AgencyId data field in the Clients table is set in the same way. So, the AgencyId of a client entered into the Clients table at Operation ID on a day of operation will be set to 0. The AgencyId of a client entered by a user representing a referring agency will be set to the AgencyId of the referring agency. Clients are tagged in this way to allow Operation ID users to see all clients and to allow a users from a referring agency to see only the clients referred by that agency.","title":"The AgencyId Data Field in table AspNetUsers"},{"location":"Implementation/#date-management","text":"Dates are treated differently at AppHarbor from the way they are treated on the desktop. In both environments, a date is stored as the midnight hour. For example, March 26, 2020 is stored as 2020-03-26:00:00:00:000 in the desktop database as well as in the AppHarbor database. But if this date is stored in a ClientViewModel object and reported as the value of a jqGrid column using the date formatter, then the desktop reports it as 03/26/2020 whereas AppHarbor reports it as 03/25/2020. It is not clear why this happens, but a way to make both environments report 03/26/2020 is to offset the value stored in the view model by 12 hours to noon (2020-03-26:12:00:00:000). This is for done several DateTime data fields in Clients.ClientEntityToClientViewModel. (A 1 hour offset was tried first, but it did not work.) The same 12 hour offsetting was done with the Date field in a VisitViewModel. This can be found on file DAL/Visits.cs. When a jqGrid row containing a date is edited the date posted to the server is the midnight time, not the offset to noon time. When the row is retrieved in a ClientViewModel, the time will again be offset by 12 hour to noon and will thus display as intended in the jqGrid.","title":"Date management"},{"location":"Implementation/#the-servicedate-and-expiry-data-fields-in-table-clients","text":"When the TicketMaster adds a new client to the Clients* table the date the client is entered is recorded in the ServiceDate data field of table Clients . The same date is recorded in the Expiry data field. When a Case Manager user enters a new client into the Clients table, the ServiceDate data field is set to the date the client is entered, but the Expiry data field is set at least 30 days into the future. This expiry date will be printed on the Case Manager Voucher given to a client by his/her Case Manager. Application OPIDDaily will preload the Clients** table seen by the TicketMaster with any clients whose Expiry date has not yet past. This will allow a client entered by a Case Manager to be given priority service on the day he/she appears at Operation ID. It is the client's responsibility to appear at Operation ID on or before the expiry date printed on his/her voucher.","title":"The ServiceDate and Expiry data fields in Table Clients"},{"location":"Implementation/#sessionhelper","text":"The SessionHelper class found on fie DAL/SessionHelper.cs is the key method for managing state in application OPIDDaily. This class is used to store key value pairs in the sesssion context private to each authenticated user. Managing the value of NowServing is a key use of the SessionHelper. Instead of having methods called GetNowServing and SetNowServing, the SharedController uses polymorphism to define two methods called NowServing with different signatures. The NowServing method with zero arguments invokes method SessionHelper.Get and the NowServing method with optional argumnt nowServing invokes method SessionHelper.Set. These two NowServing methods are invoked by many methods on SharedController to implement editing functionality private to an authenticated user.","title":"SessionHelper"},{"location":"Implementation/#express-clients-and-existing-clients","text":"A first time client to Operation ID is referred to as an Express Client. Determining whether a given client is an Express Client is done by consulting the Apricot database to determine whether the client has a visit history . A visit history is a list of services previously performed for a client. If a client is determined to be an Express Client, then a user in the role FrontDesk (a FrontDesk admin) must use the OPIDDaily interface to edit the client and mark him/her as an Express Client. If consulting the Apricot database indicates that a client has a previous service history at Operation ID, then a FrontDesk admin must use the OPIDDaily interface to copy the history of previous visits to the Visits table. This table is related to the Clients table by a foreign key relationship. See the section Entity Framework Code First on the Infrastructure tab for a discussion of this foreign key relationship. Method AddClient of the SharedController receives the id returned by method Clients.AddVisit. This id will be the id of the client inserted into the Clients table. See this StackOverflow article for an explantion of the side effect of record insertion relied upon for this. The client with this id will become the NowServing client. (See the section NowServing.) The foreign key relationship existing between tables Clients and Visits is not supported by a cascading delete; deleting a client from the Clients table does not by default perform a cascading delete of any related records in the Visits table. The cascading delete must be performed manually. To see how this is done, see method RemoveClients in the SuperadminController. A client not marked as an Express Client is referred to as an Existing Client. A FrontDesk admin is responsible for using the interface to distinguish between these two types of client. This has the advantage that a user in the role of Interviewer (an Interviewer admin) need not know the difference. An Interviewer admin prepares Service Tickets (see next section) which automatically include the service history which has been recorded by a FrontDesk admin for Existing Clients.","title":"Express Clients and Existing Clients"},{"location":"Implementation/#service-tickets","text":"A primary goal of application OPIDDaily is the production of Service Tickets . A service ticket is a single piece of paper that shows the services requested by a given client together with the documents the client is supplying in support of his/her service request. In addition a service ticket provides a history of service requests from previous visits by the client, if any. Service Tickets are produced by an Interviewer Admin. The interviewing process begins by determining the service needs of a client together with documents the client is supplying in support of those needs. An Interviewer admin will use the OPIDDaily interface to capture this information. A client's history of previous visits to Operation ID will have already been recorded by a FrontDesk admin by consulting the Apricot database. After the Service Ticket for a client has been produced, an Interviewer admin will assist the client in filling out paperwork in support of service sought. It is suggested that a client's Service Ticket be forwarded to a BackOffice admin before work on a client's paperwork begins. By passing the Service Ticket to a BackOffice admin, a client's service voucher(s) can be cut and recorded in Apricot while the client is busy with paperwork. In effect a client's BackOffice stage can proceed in parallel with his/her Interviewing stage once the Service Ticket has been produced.","title":"Service Tickets"},{"location":"Implementation/#signalr","text":"Application OIDDaily uses version 2.4.1 of the JavaScript SignalR package installed via NuGet. SignalR is a push-technology used to inform authenticated users about the progress of an Operation ID client as he/she passes through the Operation ID pipeline. The SignalR connection hub is defined on file DAL/DailyHub.cs. Invoking a method of DailyHub in the server side code causes a push-notification to go out to all clients registered to the hub. For example, when a FrontDesk admin adds a new client to the jqGrid managed by the FrontDeskController, the method SharedController.AddClient will invoke DailyHub.Refresh. A call to the line hubContext.Clients.All.refreshPage(); will send a push notification to all registered clients of the hub. Those clients listening for this notification, for example the view Interviewer/Clients.cshtml, will act upon the notification. In this case, the action will be to refresh the jqGrid of clients displayed by the grid. In this way this grid is kept in synch with the grid to which the client was added by the FrontDesk admin. SignalR is also used by both the special users Client1 and Client2 to refresh the tablet computer displays used by these users. (See the section Managing Users on the Database tab.)","title":"SignalR"},{"location":"Infrastructure/","text":"Infrastructure The infrastructure of project OPIDDaily refers to the tools and technologies used to develop it, exclusive of the implementation itself. This section will be useful to a developer wanting to maintain and further develop OPIDDaily. It describes both the desktop development environment and the AppHarbor deployment environment for the web application OPIDDaily. Hosting Environments There are 3 hosting environments for OPIDDaily: desktop, staging and production. They differ in the database connection string used by each. The connection string is configured as the value of variable SQLSERVER_CONNECTION_STRING in the <appSettings> section of Web.config. The static value configured there is used by the desktop environment. The static value is overwritten by injection (at AppHarbor) when OPIDDaily is deployed to create either a staging or production release. The transformation files Web.Staging.config and Web.Release.config play a role in these deployments. The staging deployment at AppHarbor (called StageDaily) has its Environment variable set to Staging to force Web.Staging.config to be used upon deployment. This is done in the Settings section of the deployed application. The production deployment at AppHarbor has its Environment variable set to Release by default. This causes Web.Release.config to be used upon deployment. Visual Studio Project The Visual Studio 2019 (Community Edition) project representing application OPIDDaily was developed using an ASP.NET Identity 2.0 sample project developed by Syed Shanu as a starting point. The project is described in the excellent CodeProject article ASP.NET MVC Security and Creating User Role . The sample project uses the Visual Studio MVC5 project template and makes use of Katana OWIN middleware for user authentication. The use of Katana is built into the ASP.NET Identity 2.0 provider used by the project template, as is explained in the CodeProject article. On the Properties page of the Visual Studio project, remember to select Local IIS as the server and click the Create Virtual Directory button to set http://localhost/OpidDaily as the Project Url. These two actions create an application called OpidDaily under the Default Web Site in IIS and enable project OpidDaily to be run in a desktop version of IIS under this Url. Without this, the desktop IIS cannot be used to host the application. See the section on configuring IIS below. New development in the OPIDDaily Visual Studio project will be done in the staging branch and deployed to the stagedaily application at AppHarbor. (See the section on Deployment.) After changes to the staging branch have been tested in the desktop environment, using the Visual Studio GitHub interface they will be committed and then pushed to the staging branch at GitHub. After changes have been tested, they will be merged into the master branch of the project and from there deployed to application OPIDDaily at Appharbor. When the codebase is installed on a developer's Visual Studio instance on his/her machine by cloning the GitHub repository OPIDDaily , the developer must use Visual Studio to create a staging branch and then rebase this branch onto origin/master . This will cause the remote changes to appear in the local staging branch without the need to Fetch and Pull them as is done between a remote master branch and a local master branch. SQL Server Express and SSMS The desktop version of OPIDDaily makes use of a SQL Server Express to store information about clients. The database is managed by v18.0 of SQL Server Management Studio (SSMS). Visual Studio includes the ability to view an installed SQL Server Express database, but it is more convenient to have SQL Server Management Studio available for this purpose. SQL Server Express and SSMS require separate (lengthy) downloads. The SQL Server Express database for OPIDDaily was created by executing the SQL query create database OPIDDailyDB executed inside of SSMS. With this database selected in SSMS, there are two SQL queries that need to be executed to enable IIS to talk to SQL Server Express. The first query is CREATE USER [NT AUTHORITY\\NETWORK SERVICE] FOR LOGIN [NT AUTHORITY\\NETWORK SERVICE] WITH DEFAULT_SCHEMA = dbo; This query creates the database user NT AUTHORITY\\NETWORK SERVICE. The second query is EXEC sp_addrolemember 'db_owner', 'NT AUTHORITY\\NETWORK SERVICE' This query grants user NT AUTHORITY\\NETWORK SERVICE the necessary permissions to communicate with IIS. These same two queries do not need to be executed in the AppHarbor database to prepare it to communicate with IIS. See below for information about the AppHarbor deployment of OPIDDaily. It is also necessary to change the application pool identity of application OPIDDaily running under IIS to NETWORKSERVICE. See the section on configuring IIS. There is a bug in SSMS v18.0 that causes it to stop after launch; the splash screen will display and then SSMS will quit. The fix for this is to edit file ssms.exe.config found in folder C:\\\\Program Files (x86)\\Microsoft SQL Server Management Studio 18\\Common7\\IDE and remove (or comment out) the line which has the text: <NgenBind_OptimizeNonGac enabled=\"1\" /> This should be around line 38. Then restart SSMS. SSMS v18.0 does not have the capability to generate database diagrams. Previous versions of SSMS had this capability, but it was removed from v18.0. The capability has been added back to newer version of SSMS. Entity Framework Code First An application based on Entity Framework Code First may have multiple data contexts referencing a single database, as is the case for application OPIDDaily. In application OPIDDaily a data context is reserved for database migrations used by the ASP.NET Identity subsystem. Supporting multiple data contexts was enabled by some manual scaffolding in the codebase. In the case of the OPIDDaily application this scaffolding consisted of creating a project folder called DataContexts with two subfolders: IdentityMigrations and OPIDDailyMigrations. Also, a new folder called Entities was added to the OPIDDaily Visual Studio Solution to contain the classes defining the entities used by the solution. Before the code was run for the first time, the PowerShell command PM> Enable-Migrations -ContextTypeName OPIDDaily.DataContexts.IdentityDb -MigrationsDirectory DataContexts\\IdentityMigrations was executed. This created the two files DataContexts\\IdentityMigrations\\Configuration.cs DataContexts\\IdentityMigrations\\IdentityDB.cs which initiaized the IdentityDB data context. It is worth taking a look at these two files. In particular, the file IdentityDB.cs was edited to point to the application connection string through Config.ConnectionString. Executing the above PowerShell command allows the ASP.NET Identity system to automatically update the OPIDDailyDB with the ASP.NET Identity tables the first time the program is run. Running the program for the first time on the local IIS also automatically created the migration DataContexts\\IdentityMigrations\\201906051504117_InitialCreate.cs which specifies the code used to create the ASP.NET Identity tables. It is worth taking a look at this file. The first time the program was run, the Superadmin user, sa, was created in table AspNetUsers of the OPIDDaily database. (See the Database Diagram section on the Database tab.) User sa was created by method Startup.Configuration (part of Katana middleware) on the toplevel file Startup.cs. This file specifies the user sa as the first user in role SuperAdmin (created on the file). It also points to the toplevel file Config.cs through the reference Config.SuperadminPassword, where the password of user sa is configured. This project used as its starting point the excellent CodeProject article ASP.NET MVC Security and Creating User Role It was necessary to move the class ApplicationDbContext from file Models\\IdentityModels.cs on the sample project to file DataContexts/IdentityDb.cs to make things work. The PowerShell command PM> Enable-Migrations -ContextTypeName OPIDDaily.DataContexts.OPIDDailyDB -MigrationsDirectory DataContexts\\OPIDDailyMigrations was executed to initialize the OPIDDaily data context. This created the two files DataContexts\\OPIDDailyMigrations\\Configuration.cs DataContexts\\OPIDDailyMigrations\\OPIDDailyDB.cs It is worth studying these two files. The first entity added to the OPIDDaily project was the class Entities\\Client.cs . This entity was connected to the OPIDDDaily data context by the inclusion of the declaration public DbSet<Client> Clients { get; set; } on file DataContexts\\OpidDailyDB.cs. Running the PowerShell command PM> add-migration -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration \"Clients\" caused the migration 201906152111225_Clients.cs to be added to DataContexts\\OPIDDailyMigrations. Running the PowerShell command PM> update-database -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration then caused table Clients to be created in database OPIDDailyDB by executing the Up method of the above migration. Notice that the Up method refers to two database columns, ReferralDate and AppearanceDate, which are not in the currently deployed version of table Clients. The data migration 201907122132153_RemoveTwoDates.cs was used to remove these columns when it was realized they would not be needed. The second entity to be added to project OPIDDaily was the class Entities\\Visit.cs . This entity was connected to the OPIDDaily data context by the inclusion of the declaration public DbSet<Visit> Visits { get; set; } on file DataContexts\\OpidDailyDB.cs. Since table Visits was intended to be related to table Clients in the OPIDDailyDB by a foreign key, the declaration public ICollection<Visit> Visits { get; set; } was added to class Entities\\Client.cs . Entity Framework Code First automatically detected this when the \"History\" migration (described next) was created. Running the PowerShell command PM> add-migration -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration \"History\" then caused the migration 2019071220006570_History.cs to be added to folder DataContexts\\OPIDDailyMigrations. Studying the Up method of this migration, it is seen that the new table Visits to be created will have a foreign key relationship to table Clients . Running the PowerShell command PM> update-database -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration then caused table Visits to be created in database OPIDDailyDB by executing the Up method of the above migration. As desired, table Visits has a foreign key relationship to table Clients . To see this, use SSMS to study the columns of table Visits . Each additional database change requires a pair of commands: an add-migration command followed by an update-database command. Executing an add-migration command creates a .cs file in the folder associated with the ConfigurationTypeName. Study this .cs file before executing the update-database command. If the database changes indicated in the .cs file are not correct, simply delete the .cs file before running the update-database command and then try again. To generate a script for the most recent migration(s), go back in the migration history to where the recent migrations start. For example, the migration preceding the migration ExpressClient was the migration PXXA. Therefore, to get a script for migration ExpressClient, execute the command update-database -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration -Script -SourceMigration:PXXA The generated script can be run against the database at AppHarbor using SSMS. The script should be run before the code is updated at AppHarbor. executed at AppHarbor, the script will update the _MigrationHistory as well. If the script involves adding a table, then running it before the code is updated at AppHarbor will ensure that the table is ready for use when the code that references it is deployed. Configuring IIS Development of the OPIDDaily application was performed under IIS on the localhost machine. This was done so that the development environment would match the deployment environment at AppHarbor as closely as possible. The localhost application server, Internet Information Services (IIS), was not pre-installed on the localhost; however, it is part of the operating system that can easily be activated. To activate IIS, go to the Programs section of the Control Panel and turn on the IIS feature: Programs > Programs and Features > Turn Windows features on or off > Internet Information Services After checking this box, expand it by clicking the plus sign (+) next to it and go to the section World Wide Web Services > Application Development Features In this section, check the checkboxes for ASP ASP.NET 3.5 ASP.NET 4.6 if they are not already checked. This will cause additional Application Pools to be made available to IIS. The OPIDDaily application is installed as an application under the Default Web Site in IIS as described in the section describing the Visual Studio Project. The Basic Settings dialog box for application OPIDDaily (accessible from the Actions pane of IIS), will give the physical path to the folder containing the source code as C:\\VS2019Projects\\OpidDaily\\OpidDaily This folder contains the project solution file, OPIDDaily.sln. Do not change it! Application OPIDDaily must be configured to use the application pool .NET v4.5. in the Basic Settings dialog box. (This application pool became available by enabling the features described above.) Finally, change the application identity of the selected application pool (.NET v4.5) to NetworkService. To do this, highlight Application Pools on the IIS Connections panel. This will cause the available application pools to appear in the IIS body panel. Highlight the .NET v4.5 application pool and then select Set Application Pool Defaults\u2026 to display a dialog box that will enable you to change the identity of the application pool. The dialog box is reachable either from the context menu of the highlighted application pool (under right mouse click) or from the Actions panel on the right of the IIS display. The dialog box contains a section labeled Process Model which contains an entry labeled Identity. Selecting the Identity entry adds an ellipsis next to the bold ApplicationPoolIdentity. Selecting the ellipsis brings up a dialog box with the pre-selected radio button Built-in account. Select NetworkService from the dropdown menu associated with this radio button. After approving this selection, the Identity column of the application pool .NET v4.5 will show NetworkService. See the section on SQL Server Express for how to establish user NetworkService. Git for Windows Visual Studio 2019 (Community Edition) comes with built-in support for GitHub. A new project can be added to Git source control on the desktop by simply selecting Add to Source Control from the context menu of the Solution file in the Solution Explorer. Once a project is under Git source control it can be added to a remote GitHub repository by using tools available through Visual Studio. However, a technique preferred by many developers is to use Git for Windows . Git for Windows provides a BASH shell interface to GitHub which uses the same set of commands available at GitHub itself. Git for Windows integrates with Windows Explorer to allow a BASH shell to be opened on a project that has been added to a desktop Git repository. Simply point Windows Explorer at the folder containing the project solution file and select Git BASH Here from the context menu of the folder to open a Git for Windows BASH shell. Then execute Git commands from this shell window. Git for Windows also offers Git GUI, a graphical version of most Git command line functions. To open Git GUI simply select Git GUI Here from Windows Explorer. GitHub Application OPIDDaily is stored at GitHub as a repository under an account with the email address peter3418@ymail.com and account name tmhsplb. Only user tmhsplb can deploy directly to this repository. Any other user needing to deploy a version of OPIDDaily to this repository must be declared a collaborator on repository OPIDDaily by user tmhsplb. A collaborator is a user associated with a different account established at GitHub. Git for Windows was used to create a remote to save to this GitHub account. The remote was created in the Git BASH shell by opening the shell on the folder which contains the OPIDDaily.sln file (folder C:/VS2019Projects/OPIDDaily/OPIDDaily ) and issuing the command git remote add origin https://github.com/tmhsplb/opiddaily.git Creating this remote only needs to be done once, because Git for Windows stores the remote. To remove a remote use the command git remote rm myremote The need for this may arise if there was a typo in the creation of myremote. AppHarbor AppHarbor (appharbor.com) is a Platform as a Service Provider which uses Amazon Web Services infrastructure for hosting applications and Git as a versioning tool. When an application is defined at AppHarbor, a Git repository is created to manage versions of the application's deployment. The OPIDDaily application is defined as an application at AppHarbor to create the production repository of the desktop application. The staging version of the desktop application is defined by a repository called stagedaily. The remote configured for OPIDDaily at AppHarbor is: https://tmhsplb@appharbor.com/opiddaily.git This remote is configured from a Windows Git BASH shell by the command git remote add opiddaily https://tmhsplb@appharbor.com/opiddaily.git After the remote is configured in the Git BASH shell, issuing the command git push opiddaily master will deploy the master branch of solution opiddaily to AppHarbor as application OPIDDaily, accessible through the URL https://opiddaily.apphb.com If you reset your password at AppHarbor, the 'git push' command will no longer work from the Git BASH shell. You need to have Git prompt you for your new password. To do this on a Windows 10 machine, go to Control Panel > User Accounts > Credential Manager > Windows Credentials and remove the AppHarbor entry under Generic Credentials. The next time you push, you will be prompted for your repository password. Application OPIDDaily is deployed using the free Canoe subscription level at AppHarbor. Under a Canoe subscription, the IIS application pool of application OPIDDaily has a 20 minute timeout, which forces OPIIDDaily to spin up its resources again after 20 minutes of idle time. This has not been a problem at Operation ID, because application OPIDDaily is in continuous use on the days Operation ID is open. However, the 20 minute timeout for the free Canoe version at AppHarbor would become a problem if OPIDDaily were extended to add features suitable for use by agencies that partner with Operation ID. These agencies would require that OPIDDaily be available on demand. On demand service would require the use of a paid subscription level at AppHarbor. The free Yocto version of SQL Server is used as an add-on to the OPIDDaily deployment. The Yocto version has a limit of 20MB of storage space, which is adequate for many days of usage by Operation ID. However, the database usage must be monitored to avoid exceeding the 20MB limit. See the Database Utilization section on the Database tab for how to do this. A paid subscription to a SQL Server at AppHarbor would alleviate this problem. A staging version of application OPIDDaily was created by creating an application called stagedaily at AppHarbor. DO NOT CREATE A SEPARATE REPOSITORY FOR STAGEDAILY AT GITHUB. The remote configured for stagedaily at AppHarbor is: https://tmhsplbt@appharbor.com/stagedaily.git This remote is configured from a Windows Git BASH shell by the command git remote add stagedaily https://tmhsplb@appharbor.com/stagedaily.git After the remote is configured in the Git BASH shell, issuing the command git push stagedaily staging will deploy the staging branch of OPIDDaily to AppHarbor as application stagedaily, accessible through the URL https://stagedaily.apphb.com All the tables created by Entity Framework migrations magically appeared in the staging version. The magic was probably caused by deployment of the codebase of the staging branch to AppHarbor. This branch contains all the migrations used by the master branch. However, there was one table missing: the Invitations table. This table is not included in any migration, so it has to be added manually to the staging database. This is a simple matter of using SSMS to script the table and executing the script (in SSMS) against the staging database. The scripts that needed to run on the desktop to establish the connection between Visual Studio and the desktop SQL Server did not need to be run against the staging database to establish communication with the AppHarbor server. It is possible to use AppHarbor to generate a custom domain name for an application, but this has not been done for the OPIDDaily application. On June 6, 2019 I ran into a problem when I first pushed my OPIDDaily solution from my laptop to its GitHub repository and tried to pull the resulting solution onto my desktop computer. When I tried to run the solution from my desktop it complained about missing part of the path /bin/roslyn/csc.exe. I found a fix that worked at StackOverflow https://stackoverflow.com/questions/32780315/could-not-find-a-part-of-the-path-bin-roslyn-csc-exe There were many proposed fixes, but the one that looked easiest to try was: unload project OPIDDaily and then reload it. This was the first fix I tried and it worked! Deployment This section summarizes deployment to AppHarbor. Much of the information here can be found in the section on AppHarbor. There are two applications at AppHarbor: opiddaily and stagedaily. Application opiddaily is the deployment of the Visual Studio master branch of solution OPIDDaily. Application stagedaily is the deployment of the Visual Studio staging branch of solution OPIDDaily. After configuring the opiddaily remote the Visual Studio production branch can be deployed to AppHarbor by using the Git BASH Shell command git push opiddaily master AppHarbor will automatically deploy application OPIDDaily if the push results in a successful build. After AppHarbor finishes building and deploying the code, application OPIDDaily can be viewed at https://opiddaily.apphb.com After configuring the staging remote (see above) the Visual Studio staging branch can be deployed to AppHarbor by using the Git BASH Shell command git push stagedaily staging AppHarbor will not automatically deploy application stagedaily even if the build is successful. It is necessary to click on the Deploy button at AppHarbor to deploy a successful build of application stagedaily. This may be by design if application stagedaily is recognized as a GitHub branch of application OPIDDaily. After clicking the Deploy button at AppHarbor to deploy a successful build of application stagedaily, the application can be viewed at https://stagedaily.apphb.com Although there are two applications at AppHarbor, there is only a single repository at GitHub. The name of this single repository is OPIDDaily. The repository is by default focused on the master branch of the codebase but can be switched to the staging branch by using the GitHub interface. jqGrid Almost every page of the application OPIDDaily features a grid produced by the jQuery jqGrid component. It was installed into the OPIDDaily project by using the Package Manager command: PM> Install-Package Trirand.jqGrid -Version 4.6.0 There is a collection of jqGrid Demos that was very helpful during the development of OPIDDaily. ELMAH Unhandled application errors are caught by ELMAH. Version 2.1.2 of Elamh.Mvc was installed in project OPIDDaily by using the Visual Studio NuGet package manager. By default, the ELMAH log can only be viewed on the server that hosts the application in which ELMAH is installed. To make the ELMAH log visible to a client remotely running the application, add <elmah> <security allowRemoteAccess=\"1\" /> </elmah> to the <configuration> section of file Web.config. To see ELMAH in action, modify the URL in the browser address bar to, for example, opiddaily.apphb.com/Admin/Foo This will generate an unhandled error because the MVC routing system will not be able to resolve the URL. Then go to opiddaily.apphb.com/elmah.axd to see that this error has been caught by ELMAH. On the localhost use localhost/opiddaily/elmah.axd to see the list of ELMAH errors. Installation of the Elmah.Mvc package adds the necessary DLL's and makes the necessary changes to Web.config to configure ELMAH for use. By default ELMAH will write to a database table called ELMAH_Error. The DDL Script definition of this table is found in a separate download . Download the DDL Script for MS SQL Server from the referenced web page. The script is a .SQL file which may be executed as a query inside SSMS to create table ELMAH_Error. The ELMAH log is configured by the connection string named OPidDailyConnectionString on Web.config. The value of this connection string is overwritten when the application is deployed to AppHarbor. See the Connection String section of the Database tab. The <sytem.web> section of Web.config must configure <httpHandlers> <add verb=\"POST,GET,HEAD\" path=\"elmah.axd\" type=\"Elmah.ErrorLogPageFactory, Elmah\" /> </httpHandlers> and the <system.webServer> section must configure <handlers> <add name=\"Elmah\" verb=\"POST,GET,HEAD\" path=\"elmah.axd\" type=\"Elmah.ErrorLogPageFactory, Elmah\" /> </handlers> in order for ELMAH to log both on the local IIS and on the remote server at AppHarbor. It is also necessary to set the connection string alias as described in the Connection String section of the Database tab. log4net Application logging is handled by Version 2.0.8 of log4net by the Apache Software Foundation. This package was installed using the Visual Studio NuGet package manager. The application log for project OPIDDaily is maintained as a database table as described in this article describing the AdoNetAppender for log4net. The article includes a script for creating table Log (renamed AppLog in application OPIDDaily). The script must be executed as a query in SSMS to create table AppLog in the database. Table AppLog is created by the following script: CREATE TABLE[dbo].[AppLog] ( [Id][int] IDENTITY(1, 1) NOT NULL, [Date][datetime] NOT NULL, [Thread][varchar](255) NOT NULL, [Level][varchar](50) NOT NULL, [Logger][varchar](255) NOT NULL, [Message][varchar](max) NOT NULL, [Exception][varchar](max) NULL) The application log is configured by the connection string named OpidDailyConnectionString on Web.config. The value of this connection string is overwritten when the application is deployed to AppHarbor. See the Connection String section of the Database tab. log4net requires some additional configuration in Web.config. In the section add: After the section add the definition of the AdoNetAppender: log4net must be initialized on file Global.asax.cs by including the configuration statement log4net.Config.XmlConfigurator.Configure(); Without this statement nothing will work even if log4net is correctly configured on Web.config. MkDocs This document was created using MkDocs as was the MkDocs website itself. MkDocs was installed following the guide on this page . This guide is useful for setting up the environment; however, the syntax for the file mkdocs.yml has changed from that described in the guide. The new syntax can be found at in the User Guide section of this document . An MkDocs document is a static website and can be hosted by any service that supports static sites. This MkDocs document is hosted by GitHub Pages . The Atom open source text editor was used to develop the document on the desktop. An MkDocs document uses HTML Markdown for a desktop development version of a document. GitHub provides a cheatsheet for Markdown syntax . MkDocs provides a built-in preview server. To start this server, open a BASH Shell on the folder containing the mkdoc.yml file of the project and execute mkdocs serve Then go to http://127.0.0.1:8000 in a desktop browser. Pages can be edited and saved while in preview mode. The changes will be reflected in the browser document. When it is time to publish a version of a document, in a Git BASH shell opened on the folder containing the mkdocs.yml file, issue the command mkdocs build to expand the Markdown version of the document into an HTML version in the /site folder. Then open the Git GUI on the folder containing the mkdocs.yml file and use the GUI to create a new Git repository on the local disk. Next at GitHub create repository opiddailydoc to hold the documentation. Then create a repository on the desktop machine to associate with the GitHub repository. Issue the following command in the folder containing the mkdocs.yml file: git init After this, in the folder containing the mkdocs.yml file, define a remote called origin for the document: git remote add origin https://github.com/tmhsplb/opiddailydoc.git This command references the GitHub repository opiddailydoc. The remote only needs to be defined once. It will be remembered by the Git BASH shell. In the shell issue the following commands: git add -A git commit -a -m 'Initial commit' git push origin master This will push the master branch of the document to the repository identified by the remote called origin. Then click on the Settings tab for the newly created repository and scroll down to the GitHub Pages section. Select the master branch source and click on the Save button. Finally, to view the published document go to: https://tmhsplb.github.io/opiddailydoc/site Unless a new file is added to file mkdocs.yml , subsequent edits only require the commands mkdocs build git commit -a -m '<Comment for new commit>' git push origin master to update repository opiddailydoc at GitHub. If a new file is added to mkdocs.yml then git add -A must be run before the mkdocs build command is run. This causes any new files to be added to the local git repository. In either case it may take several minutes before edits are available.","title":"Infrastructure"},{"location":"Infrastructure/#infrastructure","text":"The infrastructure of project OPIDDaily refers to the tools and technologies used to develop it, exclusive of the implementation itself. This section will be useful to a developer wanting to maintain and further develop OPIDDaily. It describes both the desktop development environment and the AppHarbor deployment environment for the web application OPIDDaily.","title":"Infrastructure"},{"location":"Infrastructure/#hosting-environments","text":"There are 3 hosting environments for OPIDDaily: desktop, staging and production. They differ in the database connection string used by each. The connection string is configured as the value of variable SQLSERVER_CONNECTION_STRING in the <appSettings> section of Web.config. The static value configured there is used by the desktop environment. The static value is overwritten by injection (at AppHarbor) when OPIDDaily is deployed to create either a staging or production release. The transformation files Web.Staging.config and Web.Release.config play a role in these deployments. The staging deployment at AppHarbor (called StageDaily) has its Environment variable set to Staging to force Web.Staging.config to be used upon deployment. This is done in the Settings section of the deployed application. The production deployment at AppHarbor has its Environment variable set to Release by default. This causes Web.Release.config to be used upon deployment.","title":"Hosting Environments"},{"location":"Infrastructure/#visual-studio-project","text":"The Visual Studio 2019 (Community Edition) project representing application OPIDDaily was developed using an ASP.NET Identity 2.0 sample project developed by Syed Shanu as a starting point. The project is described in the excellent CodeProject article ASP.NET MVC Security and Creating User Role . The sample project uses the Visual Studio MVC5 project template and makes use of Katana OWIN middleware for user authentication. The use of Katana is built into the ASP.NET Identity 2.0 provider used by the project template, as is explained in the CodeProject article. On the Properties page of the Visual Studio project, remember to select Local IIS as the server and click the Create Virtual Directory button to set http://localhost/OpidDaily as the Project Url. These two actions create an application called OpidDaily under the Default Web Site in IIS and enable project OpidDaily to be run in a desktop version of IIS under this Url. Without this, the desktop IIS cannot be used to host the application. See the section on configuring IIS below. New development in the OPIDDaily Visual Studio project will be done in the staging branch and deployed to the stagedaily application at AppHarbor. (See the section on Deployment.) After changes to the staging branch have been tested in the desktop environment, using the Visual Studio GitHub interface they will be committed and then pushed to the staging branch at GitHub. After changes have been tested, they will be merged into the master branch of the project and from there deployed to application OPIDDaily at Appharbor. When the codebase is installed on a developer's Visual Studio instance on his/her machine by cloning the GitHub repository OPIDDaily , the developer must use Visual Studio to create a staging branch and then rebase this branch onto origin/master . This will cause the remote changes to appear in the local staging branch without the need to Fetch and Pull them as is done between a remote master branch and a local master branch.","title":"Visual Studio Project"},{"location":"Infrastructure/#sql-server-express-and-ssms","text":"The desktop version of OPIDDaily makes use of a SQL Server Express to store information about clients. The database is managed by v18.0 of SQL Server Management Studio (SSMS). Visual Studio includes the ability to view an installed SQL Server Express database, but it is more convenient to have SQL Server Management Studio available for this purpose. SQL Server Express and SSMS require separate (lengthy) downloads. The SQL Server Express database for OPIDDaily was created by executing the SQL query create database OPIDDailyDB executed inside of SSMS. With this database selected in SSMS, there are two SQL queries that need to be executed to enable IIS to talk to SQL Server Express. The first query is CREATE USER [NT AUTHORITY\\NETWORK SERVICE] FOR LOGIN [NT AUTHORITY\\NETWORK SERVICE] WITH DEFAULT_SCHEMA = dbo; This query creates the database user NT AUTHORITY\\NETWORK SERVICE. The second query is EXEC sp_addrolemember 'db_owner', 'NT AUTHORITY\\NETWORK SERVICE' This query grants user NT AUTHORITY\\NETWORK SERVICE the necessary permissions to communicate with IIS. These same two queries do not need to be executed in the AppHarbor database to prepare it to communicate with IIS. See below for information about the AppHarbor deployment of OPIDDaily. It is also necessary to change the application pool identity of application OPIDDaily running under IIS to NETWORKSERVICE. See the section on configuring IIS. There is a bug in SSMS v18.0 that causes it to stop after launch; the splash screen will display and then SSMS will quit. The fix for this is to edit file ssms.exe.config found in folder C:\\\\Program Files (x86)\\Microsoft SQL Server Management Studio 18\\Common7\\IDE and remove (or comment out) the line which has the text: <NgenBind_OptimizeNonGac enabled=\"1\" /> This should be around line 38. Then restart SSMS. SSMS v18.0 does not have the capability to generate database diagrams. Previous versions of SSMS had this capability, but it was removed from v18.0. The capability has been added back to newer version of SSMS.","title":"SQL Server Express and SSMS"},{"location":"Infrastructure/#entity-framework-code-first","text":"An application based on Entity Framework Code First may have multiple data contexts referencing a single database, as is the case for application OPIDDaily. In application OPIDDaily a data context is reserved for database migrations used by the ASP.NET Identity subsystem. Supporting multiple data contexts was enabled by some manual scaffolding in the codebase. In the case of the OPIDDaily application this scaffolding consisted of creating a project folder called DataContexts with two subfolders: IdentityMigrations and OPIDDailyMigrations. Also, a new folder called Entities was added to the OPIDDaily Visual Studio Solution to contain the classes defining the entities used by the solution. Before the code was run for the first time, the PowerShell command PM> Enable-Migrations -ContextTypeName OPIDDaily.DataContexts.IdentityDb -MigrationsDirectory DataContexts\\IdentityMigrations was executed. This created the two files DataContexts\\IdentityMigrations\\Configuration.cs DataContexts\\IdentityMigrations\\IdentityDB.cs which initiaized the IdentityDB data context. It is worth taking a look at these two files. In particular, the file IdentityDB.cs was edited to point to the application connection string through Config.ConnectionString. Executing the above PowerShell command allows the ASP.NET Identity system to automatically update the OPIDDailyDB with the ASP.NET Identity tables the first time the program is run. Running the program for the first time on the local IIS also automatically created the migration DataContexts\\IdentityMigrations\\201906051504117_InitialCreate.cs which specifies the code used to create the ASP.NET Identity tables. It is worth taking a look at this file. The first time the program was run, the Superadmin user, sa, was created in table AspNetUsers of the OPIDDaily database. (See the Database Diagram section on the Database tab.) User sa was created by method Startup.Configuration (part of Katana middleware) on the toplevel file Startup.cs. This file specifies the user sa as the first user in role SuperAdmin (created on the file). It also points to the toplevel file Config.cs through the reference Config.SuperadminPassword, where the password of user sa is configured. This project used as its starting point the excellent CodeProject article ASP.NET MVC Security and Creating User Role It was necessary to move the class ApplicationDbContext from file Models\\IdentityModels.cs on the sample project to file DataContexts/IdentityDb.cs to make things work. The PowerShell command PM> Enable-Migrations -ContextTypeName OPIDDaily.DataContexts.OPIDDailyDB -MigrationsDirectory DataContexts\\OPIDDailyMigrations was executed to initialize the OPIDDaily data context. This created the two files DataContexts\\OPIDDailyMigrations\\Configuration.cs DataContexts\\OPIDDailyMigrations\\OPIDDailyDB.cs It is worth studying these two files. The first entity added to the OPIDDaily project was the class Entities\\Client.cs . This entity was connected to the OPIDDDaily data context by the inclusion of the declaration public DbSet<Client> Clients { get; set; } on file DataContexts\\OpidDailyDB.cs. Running the PowerShell command PM> add-migration -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration \"Clients\" caused the migration 201906152111225_Clients.cs to be added to DataContexts\\OPIDDailyMigrations. Running the PowerShell command PM> update-database -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration then caused table Clients to be created in database OPIDDailyDB by executing the Up method of the above migration. Notice that the Up method refers to two database columns, ReferralDate and AppearanceDate, which are not in the currently deployed version of table Clients. The data migration 201907122132153_RemoveTwoDates.cs was used to remove these columns when it was realized they would not be needed. The second entity to be added to project OPIDDaily was the class Entities\\Visit.cs . This entity was connected to the OPIDDaily data context by the inclusion of the declaration public DbSet<Visit> Visits { get; set; } on file DataContexts\\OpidDailyDB.cs. Since table Visits was intended to be related to table Clients in the OPIDDailyDB by a foreign key, the declaration public ICollection<Visit> Visits { get; set; } was added to class Entities\\Client.cs . Entity Framework Code First automatically detected this when the \"History\" migration (described next) was created. Running the PowerShell command PM> add-migration -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration \"History\" then caused the migration 2019071220006570_History.cs to be added to folder DataContexts\\OPIDDailyMigrations. Studying the Up method of this migration, it is seen that the new table Visits to be created will have a foreign key relationship to table Clients . Running the PowerShell command PM> update-database -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration then caused table Visits to be created in database OPIDDailyDB by executing the Up method of the above migration. As desired, table Visits has a foreign key relationship to table Clients . To see this, use SSMS to study the columns of table Visits . Each additional database change requires a pair of commands: an add-migration command followed by an update-database command. Executing an add-migration command creates a .cs file in the folder associated with the ConfigurationTypeName. Study this .cs file before executing the update-database command. If the database changes indicated in the .cs file are not correct, simply delete the .cs file before running the update-database command and then try again. To generate a script for the most recent migration(s), go back in the migration history to where the recent migrations start. For example, the migration preceding the migration ExpressClient was the migration PXXA. Therefore, to get a script for migration ExpressClient, execute the command update-database -ConfigurationTypeName OPIDDaily.DataContexts.OPIDDailyMigrations.Configuration -Script -SourceMigration:PXXA The generated script can be run against the database at AppHarbor using SSMS. The script should be run before the code is updated at AppHarbor. executed at AppHarbor, the script will update the _MigrationHistory as well. If the script involves adding a table, then running it before the code is updated at AppHarbor will ensure that the table is ready for use when the code that references it is deployed.","title":"Entity Framework Code First"},{"location":"Infrastructure/#configuring-iis","text":"Development of the OPIDDaily application was performed under IIS on the localhost machine. This was done so that the development environment would match the deployment environment at AppHarbor as closely as possible. The localhost application server, Internet Information Services (IIS), was not pre-installed on the localhost; however, it is part of the operating system that can easily be activated. To activate IIS, go to the Programs section of the Control Panel and turn on the IIS feature: Programs > Programs and Features > Turn Windows features on or off > Internet Information Services After checking this box, expand it by clicking the plus sign (+) next to it and go to the section World Wide Web Services > Application Development Features In this section, check the checkboxes for ASP ASP.NET 3.5 ASP.NET 4.6 if they are not already checked. This will cause additional Application Pools to be made available to IIS. The OPIDDaily application is installed as an application under the Default Web Site in IIS as described in the section describing the Visual Studio Project. The Basic Settings dialog box for application OPIDDaily (accessible from the Actions pane of IIS), will give the physical path to the folder containing the source code as C:\\VS2019Projects\\OpidDaily\\OpidDaily This folder contains the project solution file, OPIDDaily.sln. Do not change it! Application OPIDDaily must be configured to use the application pool .NET v4.5. in the Basic Settings dialog box. (This application pool became available by enabling the features described above.) Finally, change the application identity of the selected application pool (.NET v4.5) to NetworkService. To do this, highlight Application Pools on the IIS Connections panel. This will cause the available application pools to appear in the IIS body panel. Highlight the .NET v4.5 application pool and then select Set Application Pool Defaults\u2026 to display a dialog box that will enable you to change the identity of the application pool. The dialog box is reachable either from the context menu of the highlighted application pool (under right mouse click) or from the Actions panel on the right of the IIS display. The dialog box contains a section labeled Process Model which contains an entry labeled Identity. Selecting the Identity entry adds an ellipsis next to the bold ApplicationPoolIdentity. Selecting the ellipsis brings up a dialog box with the pre-selected radio button Built-in account. Select NetworkService from the dropdown menu associated with this radio button. After approving this selection, the Identity column of the application pool .NET v4.5 will show NetworkService. See the section on SQL Server Express for how to establish user NetworkService.","title":"Configuring IIS"},{"location":"Infrastructure/#git-for-windows","text":"Visual Studio 2019 (Community Edition) comes with built-in support for GitHub. A new project can be added to Git source control on the desktop by simply selecting Add to Source Control from the context menu of the Solution file in the Solution Explorer. Once a project is under Git source control it can be added to a remote GitHub repository by using tools available through Visual Studio. However, a technique preferred by many developers is to use Git for Windows . Git for Windows provides a BASH shell interface to GitHub which uses the same set of commands available at GitHub itself. Git for Windows integrates with Windows Explorer to allow a BASH shell to be opened on a project that has been added to a desktop Git repository. Simply point Windows Explorer at the folder containing the project solution file and select Git BASH Here from the context menu of the folder to open a Git for Windows BASH shell. Then execute Git commands from this shell window. Git for Windows also offers Git GUI, a graphical version of most Git command line functions. To open Git GUI simply select Git GUI Here from Windows Explorer.","title":"Git for Windows"},{"location":"Infrastructure/#github","text":"Application OPIDDaily is stored at GitHub as a repository under an account with the email address peter3418@ymail.com and account name tmhsplb. Only user tmhsplb can deploy directly to this repository. Any other user needing to deploy a version of OPIDDaily to this repository must be declared a collaborator on repository OPIDDaily by user tmhsplb. A collaborator is a user associated with a different account established at GitHub. Git for Windows was used to create a remote to save to this GitHub account. The remote was created in the Git BASH shell by opening the shell on the folder which contains the OPIDDaily.sln file (folder C:/VS2019Projects/OPIDDaily/OPIDDaily ) and issuing the command git remote add origin https://github.com/tmhsplb/opiddaily.git Creating this remote only needs to be done once, because Git for Windows stores the remote. To remove a remote use the command git remote rm myremote The need for this may arise if there was a typo in the creation of myremote.","title":"GitHub"},{"location":"Infrastructure/#appharbor","text":"AppHarbor (appharbor.com) is a Platform as a Service Provider which uses Amazon Web Services infrastructure for hosting applications and Git as a versioning tool. When an application is defined at AppHarbor, a Git repository is created to manage versions of the application's deployment. The OPIDDaily application is defined as an application at AppHarbor to create the production repository of the desktop application. The staging version of the desktop application is defined by a repository called stagedaily. The remote configured for OPIDDaily at AppHarbor is: https://tmhsplb@appharbor.com/opiddaily.git This remote is configured from a Windows Git BASH shell by the command git remote add opiddaily https://tmhsplb@appharbor.com/opiddaily.git After the remote is configured in the Git BASH shell, issuing the command git push opiddaily master will deploy the master branch of solution opiddaily to AppHarbor as application OPIDDaily, accessible through the URL https://opiddaily.apphb.com If you reset your password at AppHarbor, the 'git push' command will no longer work from the Git BASH shell. You need to have Git prompt you for your new password. To do this on a Windows 10 machine, go to Control Panel > User Accounts > Credential Manager > Windows Credentials and remove the AppHarbor entry under Generic Credentials. The next time you push, you will be prompted for your repository password. Application OPIDDaily is deployed using the free Canoe subscription level at AppHarbor. Under a Canoe subscription, the IIS application pool of application OPIDDaily has a 20 minute timeout, which forces OPIIDDaily to spin up its resources again after 20 minutes of idle time. This has not been a problem at Operation ID, because application OPIDDaily is in continuous use on the days Operation ID is open. However, the 20 minute timeout for the free Canoe version at AppHarbor would become a problem if OPIDDaily were extended to add features suitable for use by agencies that partner with Operation ID. These agencies would require that OPIDDaily be available on demand. On demand service would require the use of a paid subscription level at AppHarbor. The free Yocto version of SQL Server is used as an add-on to the OPIDDaily deployment. The Yocto version has a limit of 20MB of storage space, which is adequate for many days of usage by Operation ID. However, the database usage must be monitored to avoid exceeding the 20MB limit. See the Database Utilization section on the Database tab for how to do this. A paid subscription to a SQL Server at AppHarbor would alleviate this problem. A staging version of application OPIDDaily was created by creating an application called stagedaily at AppHarbor. DO NOT CREATE A SEPARATE REPOSITORY FOR STAGEDAILY AT GITHUB. The remote configured for stagedaily at AppHarbor is: https://tmhsplbt@appharbor.com/stagedaily.git This remote is configured from a Windows Git BASH shell by the command git remote add stagedaily https://tmhsplb@appharbor.com/stagedaily.git After the remote is configured in the Git BASH shell, issuing the command git push stagedaily staging will deploy the staging branch of OPIDDaily to AppHarbor as application stagedaily, accessible through the URL https://stagedaily.apphb.com All the tables created by Entity Framework migrations magically appeared in the staging version. The magic was probably caused by deployment of the codebase of the staging branch to AppHarbor. This branch contains all the migrations used by the master branch. However, there was one table missing: the Invitations table. This table is not included in any migration, so it has to be added manually to the staging database. This is a simple matter of using SSMS to script the table and executing the script (in SSMS) against the staging database. The scripts that needed to run on the desktop to establish the connection between Visual Studio and the desktop SQL Server did not need to be run against the staging database to establish communication with the AppHarbor server. It is possible to use AppHarbor to generate a custom domain name for an application, but this has not been done for the OPIDDaily application. On June 6, 2019 I ran into a problem when I first pushed my OPIDDaily solution from my laptop to its GitHub repository and tried to pull the resulting solution onto my desktop computer. When I tried to run the solution from my desktop it complained about missing part of the path /bin/roslyn/csc.exe. I found a fix that worked at StackOverflow https://stackoverflow.com/questions/32780315/could-not-find-a-part-of-the-path-bin-roslyn-csc-exe There were many proposed fixes, but the one that looked easiest to try was: unload project OPIDDaily and then reload it. This was the first fix I tried and it worked!","title":"AppHarbor"},{"location":"Infrastructure/#deployment","text":"This section summarizes deployment to AppHarbor. Much of the information here can be found in the section on AppHarbor. There are two applications at AppHarbor: opiddaily and stagedaily. Application opiddaily is the deployment of the Visual Studio master branch of solution OPIDDaily. Application stagedaily is the deployment of the Visual Studio staging branch of solution OPIDDaily. After configuring the opiddaily remote the Visual Studio production branch can be deployed to AppHarbor by using the Git BASH Shell command git push opiddaily master AppHarbor will automatically deploy application OPIDDaily if the push results in a successful build. After AppHarbor finishes building and deploying the code, application OPIDDaily can be viewed at https://opiddaily.apphb.com After configuring the staging remote (see above) the Visual Studio staging branch can be deployed to AppHarbor by using the Git BASH Shell command git push stagedaily staging AppHarbor will not automatically deploy application stagedaily even if the build is successful. It is necessary to click on the Deploy button at AppHarbor to deploy a successful build of application stagedaily. This may be by design if application stagedaily is recognized as a GitHub branch of application OPIDDaily. After clicking the Deploy button at AppHarbor to deploy a successful build of application stagedaily, the application can be viewed at https://stagedaily.apphb.com Although there are two applications at AppHarbor, there is only a single repository at GitHub. The name of this single repository is OPIDDaily. The repository is by default focused on the master branch of the codebase but can be switched to the staging branch by using the GitHub interface.","title":"Deployment"},{"location":"Infrastructure/#jqgrid","text":"Almost every page of the application OPIDDaily features a grid produced by the jQuery jqGrid component. It was installed into the OPIDDaily project by using the Package Manager command: PM> Install-Package Trirand.jqGrid -Version 4.6.0 There is a collection of jqGrid Demos that was very helpful during the development of OPIDDaily.","title":"jqGrid"},{"location":"Infrastructure/#elmah","text":"Unhandled application errors are caught by ELMAH. Version 2.1.2 of Elamh.Mvc was installed in project OPIDDaily by using the Visual Studio NuGet package manager. By default, the ELMAH log can only be viewed on the server that hosts the application in which ELMAH is installed. To make the ELMAH log visible to a client remotely running the application, add <elmah> <security allowRemoteAccess=\"1\" /> </elmah> to the <configuration> section of file Web.config. To see ELMAH in action, modify the URL in the browser address bar to, for example, opiddaily.apphb.com/Admin/Foo This will generate an unhandled error because the MVC routing system will not be able to resolve the URL. Then go to opiddaily.apphb.com/elmah.axd to see that this error has been caught by ELMAH. On the localhost use localhost/opiddaily/elmah.axd to see the list of ELMAH errors. Installation of the Elmah.Mvc package adds the necessary DLL's and makes the necessary changes to Web.config to configure ELMAH for use. By default ELMAH will write to a database table called ELMAH_Error. The DDL Script definition of this table is found in a separate download . Download the DDL Script for MS SQL Server from the referenced web page. The script is a .SQL file which may be executed as a query inside SSMS to create table ELMAH_Error. The ELMAH log is configured by the connection string named OPidDailyConnectionString on Web.config. The value of this connection string is overwritten when the application is deployed to AppHarbor. See the Connection String section of the Database tab. The <sytem.web> section of Web.config must configure <httpHandlers> <add verb=\"POST,GET,HEAD\" path=\"elmah.axd\" type=\"Elmah.ErrorLogPageFactory, Elmah\" /> </httpHandlers> and the <system.webServer> section must configure <handlers> <add name=\"Elmah\" verb=\"POST,GET,HEAD\" path=\"elmah.axd\" type=\"Elmah.ErrorLogPageFactory, Elmah\" /> </handlers> in order for ELMAH to log both on the local IIS and on the remote server at AppHarbor. It is also necessary to set the connection string alias as described in the Connection String section of the Database tab.","title":"ELMAH"},{"location":"Infrastructure/#log4net","text":"Application logging is handled by Version 2.0.8 of log4net by the Apache Software Foundation. This package was installed using the Visual Studio NuGet package manager. The application log for project OPIDDaily is maintained as a database table as described in this article describing the AdoNetAppender for log4net. The article includes a script for creating table Log (renamed AppLog in application OPIDDaily). The script must be executed as a query in SSMS to create table AppLog in the database. Table AppLog is created by the following script: CREATE TABLE[dbo].[AppLog] ( [Id][int] IDENTITY(1, 1) NOT NULL, [Date][datetime] NOT NULL, [Thread][varchar](255) NOT NULL, [Level][varchar](50) NOT NULL, [Logger][varchar](255) NOT NULL, [Message][varchar](max) NOT NULL, [Exception][varchar](max) NULL) The application log is configured by the connection string named OpidDailyConnectionString on Web.config. The value of this connection string is overwritten when the application is deployed to AppHarbor. See the Connection String section of the Database tab. log4net requires some additional configuration in Web.config. In the section add: After the section add the definition of the AdoNetAppender: log4net must be initialized on file Global.asax.cs by including the configuration statement log4net.Config.XmlConfigurator.Configure(); Without this statement nothing will work even if log4net is correctly configured on Web.config.","title":"log4net"},{"location":"Infrastructure/#mkdocs","text":"This document was created using MkDocs as was the MkDocs website itself. MkDocs was installed following the guide on this page . This guide is useful for setting up the environment; however, the syntax for the file mkdocs.yml has changed from that described in the guide. The new syntax can be found at in the User Guide section of this document . An MkDocs document is a static website and can be hosted by any service that supports static sites. This MkDocs document is hosted by GitHub Pages . The Atom open source text editor was used to develop the document on the desktop. An MkDocs document uses HTML Markdown for a desktop development version of a document. GitHub provides a cheatsheet for Markdown syntax . MkDocs provides a built-in preview server. To start this server, open a BASH Shell on the folder containing the mkdoc.yml file of the project and execute mkdocs serve Then go to http://127.0.0.1:8000 in a desktop browser. Pages can be edited and saved while in preview mode. The changes will be reflected in the browser document. When it is time to publish a version of a document, in a Git BASH shell opened on the folder containing the mkdocs.yml file, issue the command mkdocs build to expand the Markdown version of the document into an HTML version in the /site folder. Then open the Git GUI on the folder containing the mkdocs.yml file and use the GUI to create a new Git repository on the local disk. Next at GitHub create repository opiddailydoc to hold the documentation. Then create a repository on the desktop machine to associate with the GitHub repository. Issue the following command in the folder containing the mkdocs.yml file: git init After this, in the folder containing the mkdocs.yml file, define a remote called origin for the document: git remote add origin https://github.com/tmhsplb/opiddailydoc.git This command references the GitHub repository opiddailydoc. The remote only needs to be defined once. It will be remembered by the Git BASH shell. In the shell issue the following commands: git add -A git commit -a -m 'Initial commit' git push origin master This will push the master branch of the document to the repository identified by the remote called origin. Then click on the Settings tab for the newly created repository and scroll down to the GitHub Pages section. Select the master branch source and click on the Save button. Finally, to view the published document go to: https://tmhsplb.github.io/opiddailydoc/site Unless a new file is added to file mkdocs.yml , subsequent edits only require the commands mkdocs build git commit -a -m '<Comment for new commit>' git push origin master to update repository opiddailydoc at GitHub. If a new file is added to mkdocs.yml then git add -A must be run before the mkdocs build command is run. This causes any new files to be added to the local git repository. In either case it may take several minutes before edits are available.","title":"MkDocs"}]}